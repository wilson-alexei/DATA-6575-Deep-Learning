{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUx6tTPULT_z"
      },
      "source": [
        "# Deep Learning & Artificial Intelligence\n",
        "## Neural Networks Building Blocks - Loss Functions, Optimizers, and Activations\n",
        "### Dr. Jie Tao, Fairfield University"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpA9ht7iMOiM"
      },
      "source": [
        "Before you proceed with this lecture, you should read Chapter 4 on the textbook, which reviews the fundamentals of ML.\n",
        "\n",
        "In this lecture, we cover the following topics:\n",
        "- Loss Functions\n",
        "- Optimizers\n",
        "- Activations\n",
        "- Regularizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oe1uMvhSQ11"
      },
      "source": [
        "## Loss Functions\n",
        "\n",
        "- As said before, the selection of loss functions largely dependes on the analytical problem\n",
        "  - Loss function calculates the __error__, which is the difference between the predicted value $\\hat{y}$ and actual value $y$;\n",
        "  - In other words, loss values are used to calculate __gradients__, which we can used to update the weights in the NN;\n",
        "- Below animation illustrated how a loss function works\n",
        "\n",
        "![loss function](https://machinelearningknowledge.ai/wp-content/uploads/2020/10/Loss_Function.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9rtuRV2T7pK"
      },
      "source": [
        "### `keras` Loss Functions for Binary Classification\n",
        "\n",
        "- As said before, in binary classification problems, the most popular loss functions is `binary_crossentropy`\n",
        "- Keep in mind that in NN, the predicted $\\hat{y} \\in [0,1]$ - which is a real decimal number between 0 and 1, where as $y$ is either 0 or 1\n",
        "- In essence, `binary_crossentropy` is built on __Negative Log-Likelihood__ (NLL), which is defined by:\n",
        "\n",
        "$$ J(\\hat{y}, y) = -\\frac{1}{n}\\sum_{i=0}^n{[y_i \\log(\\hat{y_i}) + (1- y_i) \\log(1-\\hat{y_i})]} $$\n",
        "\n",
        "- Where:\n",
        "  - $n$ is the number of test samples;\n",
        "  - $\\hat{y_i}$ is the predicted probability of a sample being in class `1`;\n",
        "    - If $\\hat{y_i} >= 0.5 $ then the $i^{th}$ sample is predicted to be class `1` otherwise class `0`\n",
        "  - $y_i$ is the class label of the $i^{th}$ sample, either `1` or `0`\n",
        "  - $ \\log() $ is the natural ($e$ based) algorithm\n",
        "- Refer to [this article](https://towardsdatascience.com/understanding-negative-log-loss-8c3e77fafb79) if you need more help with NLL."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPpiaY5HXzlL"
      },
      "source": [
        "#### How to Use Binary Cross Entropy\n",
        "\n",
        "- The more $\\hat{y} $ and $y$ are similar, the loss is closer to 0, otherwise it is closer to $ +\\infty $\n",
        "  - If $ y = 1 $, when $\\hat{y} \\rightarrow 1 $, the $ loss \\rightarrow 0 $; when $\\hat{y} \\rightarrow 0 $, the $ loss \\rightarrow + \\infty $\n",
        "  - If $ y = 0 $, when $\\hat{y} \\rightarrow 0 $, the $ loss \\rightarrow 0 $; when $\\hat{y} \\rightarrow 1 $, the $ loss \\rightarrow + \\infty $\n",
        "- Below animation illstrates the Binary Cross Entropy.\n",
        "\n",
        "![BCE](https://machinelearningknowledge.ai/wp-content/uploads/2020/10/4.Binary_Cross_Entropy.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYWIV4eLYpbk"
      },
      "source": [
        "#### Binary Cross Entropy Example\n",
        "\n",
        "- Let's use a simple example to show BCE. Say the test set contains 2 samples:\n",
        "  - $ y_0 = 1, y_1 = 0 $\n",
        "  - after OHE, $ y_0 = [0, 1], y_1 = [1, 0] $\n",
        "- Our first model `model1` returns two predicted values:\n",
        "  - $ \\hat{y}_0^1 = [0.6, 0.4], \\hat{y}_1^1 = [0.4, 0.6] $\n",
        "  - so the predictions are `class 0` and `class 1`\n",
        "- Our second model `model2` returns two predicted values:\n",
        "  - $ \\hat{y}_0^2 = [0.4, 0.6], \\hat{y}_1^2 = [0.6, 0.4] $\n",
        "  - so the predictions are `class 1` and `class 0`\n",
        "- Our third model `model3` returns two predicted values:\n",
        "  - $ \\hat{y}_0^3 = [0.1, 0.9], \\hat{y}_1^1 = [0.9, 0.1] $\n",
        "  - so the predictions are `class 1` and `class 0`\n",
        "- Intuitively, we know `model1` is way off, `model2` and `model3` got the classifications correct but `model3` is with __more confidence__\n",
        "- Let's use these BCE to verify our intuition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xnAJANbLfxy",
        "outputId": "3fa314df-a220-4b0f-fb50-ea4948a96afd"
      },
      "source": [
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "\n",
        "y_test = [[0., 1.], [1., 0.]]\n",
        "y_pred1 = [[0.6, 0.4], [0.4, 0.6]]\n",
        "y_pred2 = [[0.4, 0.6], [0.6, 0.4]]\n",
        "y_pred3 = [[0.1, 0.9], [0.9, 0.1]]\n",
        "\n",
        "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
        "bce = BinaryCrossentropy()\n",
        "\n",
        "print('model1 loss:', bce(y_test, y_pred1).numpy())\n",
        "print('model2 loss:', bce(y_test, y_pred2).numpy())\n",
        "print('model3 loss:', bce(y_test, y_pred3).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model1 loss: 0.9162905\n",
            "model2 loss: 0.5108254\n",
            "model3 loss: 0.10536041\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZgK6zjabkz-"
      },
      "source": [
        "You can observe BCE successfully tested our both intuitions - `model2` is __more accurate__ in `model1`, and `model3` has a lower loss value.\n",
        "\n",
        "Typically, for Binary Classification, we use the `softmax` activation in the output layer to avoid this problem, which will be discussed below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc45wAzvcGUA"
      },
      "source": [
        "### `keras` Loss Function for Multi-Class Classification\n",
        "\n",
        "- Multi-class classification means we can classify the sampels into __more than 2__ classes\n",
        "- So we can use Categorical Class Entropy (CCE) as the main loss function\n",
        "  - You can think of binary classification as a special case of multi-class classification (# of classes == 2)\n",
        "  - one key difference is that when you use BCE, you can have __one__ neuron in the output layer, whereas when using CCE, you need to have $N$ neurons in the output layer, where $N$ is the number of classes\n",
        "- CCE is often used with the `softmax` activation in the output layer as well\n",
        "- A special type of CCE is called Sparse Categorical Class Entropy (SCCE)\n",
        "  - where you do not have to perform OHE on your target values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2InGYHZgiph"
      },
      "source": [
        "#### CCE Example\n",
        "\n",
        "- Let's use another simple example to illustrate CCE. Say the test set contains 2 samples for a 3-class classification\n",
        "- $ y_0 = 1, y_1 = 2 $\n",
        "  - after OHE, $ y_0 = [0, 1, 0], y_1 = [0, 0, 1] $\n",
        "- Our first model `model1` returns two predicted values:\n",
        "  - $ \\hat{y}_0^1 = [0.4, 0.6, 0.], \\hat{y}_1^1 = [0.2, 0.6, 0.2] $\n",
        "  - so the predictions are `class 1` and `class 1`\n",
        "- Our second model `model2` returns two predicted values:\n",
        "  - $ \\hat{y}_0^1 = [0.4, 0.6, 0.], \\hat{y}_1^1 = [0.2, 0.2, 0.6] $\n",
        "  - so the predictions are `class 1` and `class 2`\n",
        "- Our third model `model3` returns two predicted values:\n",
        "  - $ \\hat{y}_0^2 = [0.05, 0.95, 0.], \\hat{y}_1^2 = [0.1, 0.1, 0.8] $\n",
        "  - so the predictions are `class 1` and `class 2`\n",
        "- Intuitively, we know `model1` is way off, `model2` and `model3` got the classifications correct but `model3` is with __more confidence__\n",
        "- Let's use these CCE to verify our intuition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ik-pUWRa5xX",
        "outputId": "75e5fd20-6102-4981-9993-6b0b30f3eaee"
      },
      "source": [
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "\n",
        "y_test = [[0., 1., 0.], [0., 0., 1.]]\n",
        "y_pred1 = [[0.6, 0.4, 0.], [0.2, 0.6, 0.2]]\n",
        "y_pred2 = [[0.6, 0.4, 0.], [0.2, 0.2, 0.6]]\n",
        "y_pred3 = [[0.05,0.95,0.], [0.1,0.1,0.8]]\n",
        "\n",
        "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
        "cce = CategoricalCrossentropy()\n",
        "\n",
        "print('model1 loss:', cce(y_test, y_pred1).numpy())\n",
        "print('model2 loss:', cce(y_test, y_pred2).numpy())\n",
        "print('model3 loss:', cce(y_test, y_pred3).numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model1 loss: 1.2628644\n",
            "model2 loss: 0.71355814\n",
            "model3 loss: 0.13721842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swykh5ZZh-uz"
      },
      "source": [
        "We can observe that CCE successfully captured all of our intuitions.\n",
        "\n",
        "__PRO TIP__: this is the reason a lot of chances people use CCE over BCE even in binary classifications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZidxnfXoqSDC"
      },
      "source": [
        "### `keras` Loss Function for Regression\n",
        "\n",
        "- Compared to classification models, the loss in regression models are more straightformward, but it is the same logic:\n",
        "  - Regression loss are the error (aka. residual) of the actual values ($y$) and the predicted values ($\\hat{y}$).\n",
        "- Below animation illustrates how regression losses are calculated.\n",
        "\n",
        "![Regression Loss](https://machinelearningknowledge.ai/wp-content/uploads/2020/10/Regression_Loss.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btXPoKM3rPsO"
      },
      "source": [
        "#### Mean Square Error (MSE) Loss\n",
        "\n",
        "- MSE (or MAE) are the most popular loss function(s) used in `keras`\n",
        "- Use the example below to observe how `mse` in `keras` works"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PELyg2Evh7Bk",
        "outputId": "ac5f38e9-2a3c-49c5-8ecc-25a84f28549b"
      },
      "source": [
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "\n",
        "y_true = [[0., 1.], [0., 0.]]\n",
        "y_pred = [[1., 1.], [1., 0.]]\n",
        "# Using 'auto'/'sum_over_batch_size' reduction type.\n",
        "mse = MeanSquaredError()\n",
        "mse(y_true, y_pred).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9zW1rAjsAEP",
        "outputId": "413f8cb7-d5f7-4d01-80f3-192156d6f86d"
      },
      "source": [
        "#### Similarly for MAE\n",
        "\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "\n",
        "mae = MeanAbsoluteError()\n",
        "mae(y_true, y_pred).numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1TaBnImsUsl"
      },
      "source": [
        "### Custom Loss Functions in `keras`\n",
        "\n",
        "- Depending on your specific analytical question, the predefined loss functions may not serve the purpose\n",
        "- Luckily `keras` allows us to build our own loss fucntions, see example below:\n",
        "\n",
        "```python\n",
        "def custom_loss_function(y_true, y_pred):\n",
        "   squared_difference = tf.square(y_true - y_pred)\n",
        "   return tf.reduce_mean(squared_difference, axis=-1)\n",
        "\n",
        "model.compile(optimizer='adam', loss=custom_loss_function)\n",
        "```\n",
        "- One potential scenario is that sometimes you need to deal with classfications where different classes contains different meanings, or importances\n",
        "  - in that way, you need to penalize the __less__ important or meaningful classes\n",
        "  - Refer to page 9 - 10 of  [this article](https://github.com/DrJieTao/DeepLearning_docs/blob/main/Maymin%20NBA%20Journal%20of%20Business%20Analytics.pdf) - courtersy of Dr. Philip Maymin - for a real-life example.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IATzs8AEs32H"
      },
      "source": [
        "### Additional Resources for `keras` Loss Functions.\n",
        "\n",
        "Refer to [this post](https://towardsdatascience.com/understanding-different-loss-functions-for-neural-networks-dd1ed0274718) or [this tutorial](https://machinelearningknowledge.ai/types-of-keras-loss-functions-explained-for-beginners/) for more information of `keras` loss functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGkaVkDUtPd2"
      },
      "source": [
        "## Optimizers\n",
        "\n",
        "- From the previous lectures we already know the optimizers are used to minimize the loss (based on the loss function) during the trianing process\n",
        "- Also, most of the mainstream optimizers are variants of SGD\n",
        "- In essence, we try to find the __global minimum__ in the space defined by the loss function:\n",
        "\n",
        "![minimal](https://machinelearningknowledge.ai/wp-content/uploads/2020/12/Keras-Optimizers-Examples.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N04sR0TUuMrj"
      },
      "source": [
        "### How to Use Optimizers in `keras`\n",
        "\n",
        "To use optimizers in `keras`, we can use one of the two following ways:\n",
        "1. You can specify arguments (mostly `learning_rate`) by doing the following:\n",
        "\n",
        "```python\n",
        "opt = keras.optimizers.Adam(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt)\n",
        "```\n",
        "\n",
        "2. Just use them with the default arguments:\n",
        "\n",
        "```python\n",
        "# pass optimizer by name: default parameters will be used\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJpcYdd9x-lW"
      },
      "source": [
        "### Types of `keras` Optimizers\n",
        "\n",
        "- Stochastic Gradient Descent (SGD)\n",
        "- Adaptive Momentum Estimation (Adam)\n",
        "- Root Mean Square Propagation (RMSProp)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTI79cILNEB-"
      },
      "source": [
        "### SGD\n",
        "\n",
        "- SGD is built on the idea of __back-propgation__ (BP).\n",
        "- In every BP pass (in this case only __one__ training sample and __one__ training label), the parameters in a NN are updated via:\n",
        "\n",
        "$$ \\theta = \\theta - \\eta \\times \\nabla_{\\theta}J(\\theta; X, y)$$\n",
        "\n",
        "- In which:\n",
        "  - $ \\theta $ is one of the **parameters** in NN (weights, biases, activations)\n",
        "  - $ \\eta $ is the __learning rate__ (sometimes we use $\\alpha$ or $\\gamma$\n",
        "  - $ \\nabla$ is the __gradient__ of $J$ againsst $\\theta$\n",
        "  - $J$ is the __Loss Function__, $X$ and $y$ are the training sample and the label, respectively.\n",
        "  - $ J(\\theta; X, y)$ means for every pair of $ (X, y) $, we update $\\theta $ so it decreases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGRYJt68PMDO"
      },
      "source": [
        "#### Example: If we only have 1 parameter...\n",
        "\n",
        "![one weight example](https://mlfromscratch.com/content/images/2019/12/gradient-descent-optimized--1-.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqcbe8WOPZJs"
      },
      "source": [
        "#### Pros and Cons of SGD\n",
        "\n",
        "- Pros\n",
        "  - Relatively **fast** compared to the older gradient descent approaches\n",
        "  - SGD is comparatively **easy** to learn for beginners\n",
        "\n",
        "- Cons\n",
        "  - Converges **slower** than newer algorithms (e.g., Adam, RMSProp)\n",
        "  - Has more problems with being stuck in a *local* minimum\n",
        "  - Newer approaches **outperform** SGD in terms of optimizing the cost function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IK26Gx8sK4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8668c8f-7021-4f60-ccf7-fcc70aafdc56"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "var = tf.Variable(10.0)\n",
        "loss = lambda: (var ** 2)/2.0         # d(loss)/d(var1) = var1\n",
        "for i in range(5):\n",
        "  step_count = opt.minimize(loss, [var]).numpy()\n",
        "  # Step is `- learning_rate * grad`\n",
        "  print('the i-th step loss is:',var.numpy()) # first step: 9.0, then 8.0, then 7.0, ..."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the i-th step loss is: 9.0\n",
            "the i-th step loss is: 8.1\n",
            "the i-th step loss is: 7.2900004\n",
            "the i-th step loss is: 6.5610003\n",
            "the i-th step loss is: 5.9049\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqEZPqyoQG3y"
      },
      "source": [
        "### Adam\n",
        "\n",
        "- Performs **best** on average\n",
        "- Adam uses **Momentum** and **Adaptive Learning Rates** to converge faster\n",
        "\n",
        "![compare of optimizers](https://mlfromscratch.com/content/images/2019/12/saddle.gif)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlMafuVTRFnY"
      },
      "source": [
        "#### Momentum\n",
        "\n",
        "- __Momentum__ controls how fast we update any parameter $ \\theta $\n",
        "- At a certain time step $t$, the parameter $\\theta_{t}$ is updated via:\n",
        "\n",
        "$$ \\theta_{t} = \\theta_{t} - \\eta\\nabla J(\\theta_{t}) + \\gamma v_{t} $$\n",
        "- We know most in above equation already, the new things are:\n",
        "  - time step $t$, which means any time step (e.g., per second?) in the training process\n",
        "  - momentun term $\\gamma v_{t}$, which we will explain below\n",
        "- Essentially, we added a temporal element to the BP update process, meaning we update $\\theta$ __faster__ later in the training process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gasTx0BdTMnm"
      },
      "source": [
        "#### Momentum Term\n",
        "\n",
        "- The momentum term $\\gamma v_{t}$ contains two parts:\n",
        "  - A constant $\\gamma$ - you can think of this as the _gravitational acceleration_: if an object is in free fall (i.e., in vacuum), there is a steady gain ($ 9.84 m/s^2 $ï¼‰to the falling speed\n",
        "  - An updating speed $ v_t $: which is the sum of current update $ \\eta\\nabla J(\\theta_{t-1}) $ and the previous update $ v_{t-1} $, and $ v_{t-1} $ also includes $ v_{t-2} $ (this is called a **recursion** BTW)\n",
        "- So we are rewrite the update of $\\theta_{t}$ as:\n",
        "\n",
        "$$ \\theta_{t} = \\theta_{t} - \\eta\\nabla J(\\theta_{t}) + \\gamma \\sum_{\\tau = 1}^t{\\eta\\nabla J(\\theta_{\\tau})}$$\n",
        "\n",
        "- in which $\\tau$ refers to all the time steps, from $1$ to $t$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gqIL2tTVdmq"
      },
      "source": [
        "#### Illustration of Momentum\n",
        "\n",
        "![no momentum](https://mlfromscratch.com/content/images/2019/12/no-momentum.gif)\n",
        "\n",
        "![with momentum](https://mlfromscratch.com/content/images/2019/12/momentum.gif)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDZLMPaRVvep"
      },
      "source": [
        "#### Adaptive Learning Rates\n",
        "\n",
        "- An adaptive learning rate can be observed not only in Adam, but also in AdaGrad, AdaDelta, and RMSprop\n",
        "- The adaptive learning rate property is also known as **Learning Rate Schedules**\n",
        "- The idea is we start with _big_ steps, and finish with _small_ steps\n",
        "  - this counters the effects from momentum, just in case the steps are to big so we skip over the __global momentum__\n",
        "- The parameters are updated via:\n",
        "\n",
        "$$ \\theta_{t+1} = \\theta_{t} - \\frac{\\eta \\times \\hat{m}_{t}}{\\sqrt{\\hat{v}_{t}}+ \\epsilon} $$\n",
        "\n",
        "- in which:\n",
        "  - $ \\epsilon $ is a small number to avoid division by zero, usually $ 10^{-8}$\n",
        "  - $ \\hat{m}_t$: bias-corrected momentum, adjusted based on the loss value:\n",
        "  $$ \\hat{m}_t = \\frac{m_{t}}{1-\\beta_1}, m_{t} = (1-\\beta_1)g_t + \\beta_1m_{t-1} $$\n",
        "  - $ \\hat{v}_t$: bias-corrected momentum, adjusted based on the loss value:\n",
        "  $$ \\hat{v}_t = \\frac{v_{t}}{1-\\beta_2}, v_{t} = (1-\\beta_2)g_t^2 + \\beta_2v_{t-1} $$\n",
        "\n",
        "- Instead of using a single $\\gamma$ in momentum, we use two terms $\\beta_1$ and $\\beta_2$ to control how the learning rate is adpated. Typically, we set:\n",
        "  - $ \\beta_1 = 0.9, \\beta_2 = 0.999 $\n",
        "  - at the fifth step, $\\beta_1^{t=5} = 0.9^5 = 0.59049 $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8lw6LQnY3Lk"
      },
      "source": [
        "#### Pros of Adam\n",
        "\n",
        "- It is efficient to use and consumes very little memory.\n",
        "- It is appropriate in cases where huge amount of data and parameters are available for usage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KORhO7gbQAMD",
        "outputId": "42969bec-11f6-4b03-b147-a4aaed01cb40"
      },
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
        "var1 = tf.Variable(10.0)\n",
        "\n",
        "for i in range(20):\n",
        "  loss = lambda: (var1 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
        "  step_count = opt.minimize(loss, [var1]).numpy()\n",
        "  # The first step is `-learning_rate*sign(grad)`\n",
        "  print('the i-th step loss is:', var1.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the i-th step loss is: 9.9\n",
            "the i-th step loss is: 9.800028\n",
            "the i-th step loss is: 9.700101\n",
            "the i-th step loss is: 9.60024\n",
            "the i-th step loss is: 9.500463\n",
            "the i-th step loss is: 9.400787\n",
            "the i-th step loss is: 9.301234\n",
            "the i-th step loss is: 9.201822\n",
            "the i-th step loss is: 9.102571\n",
            "the i-th step loss is: 9.003497\n",
            "the i-th step loss is: 8.904622\n",
            "the i-th step loss is: 8.8059635\n",
            "the i-th step loss is: 8.7075405\n",
            "the i-th step loss is: 8.609371\n",
            "the i-th step loss is: 8.511473\n",
            "the i-th step loss is: 8.413864\n",
            "the i-th step loss is: 8.316562\n",
            "the i-th step loss is: 8.2195835\n",
            "the i-th step loss is: 8.122946\n",
            "the i-th step loss is: 8.026666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofl0eXU5Z25v"
      },
      "source": [
        "### RMSProp\n",
        "\n",
        "- Root Mean Squared Propagation (RMSprop) provides an *exponentially decaying average*\n",
        "- RMSProp contains the __momentum__, and a similar term in which we do __not__ consider the learning rate\n",
        "- In other optimizers, the learning rate decreases throughout the training process, where in Adam RMSProp, learning rate can go up and down\n",
        "\n",
        "![rmsprop](https://mlfromscratch.com/content/images/2019/12/rmsprop.gif)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dmxurf7KY9k1",
        "outputId": "f5793836-cc5f-466d-cd38-ac5a49adf776"
      },
      "source": [
        "opt = tf.keras.optimizers.RMSprop(learning_rate=0.1)\n",
        "var2 = tf.Variable(10.0)\n",
        "\n",
        "for i in range(20):\n",
        "  loss = lambda: (var2 ** 2)/2.0       # d(loss)/d(var1) == var1\n",
        "  step_count = opt.minimize(loss, [var2]).numpy()\n",
        "  # The first step is `-learning_rate*sign(grad)`\n",
        "  print('the i-th step loss is:', var2.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the i-th step loss is: 9.683772\n",
            "the i-th step loss is: 9.45788\n",
            "the i-th step loss is: 9.270531\n",
            "the i-th step loss is: 9.105434\n",
            "the i-th step loss is: 8.955067\n",
            "the i-th step loss is: 8.815248\n",
            "the i-th step loss is: 8.683382\n",
            "the i-th step loss is: 8.5577345\n",
            "the i-th step loss is: 8.437081\n",
            "the i-th step loss is: 8.320523\n",
            "the i-th step loss is: 8.207378\n",
            "the i-th step loss is: 8.097118\n",
            "the i-th step loss is: 7.9893227\n",
            "the i-th step loss is: 7.883653\n",
            "the i-th step loss is: 7.7798333\n",
            "the i-th step loss is: 7.6776342\n",
            "the i-th step loss is: 7.5768642\n",
            "the i-th step loss is: 7.477362\n",
            "the i-th step loss is: 7.3789907\n",
            "the i-th step loss is: 7.2816324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiwp969eexFs"
      },
      "source": [
        "### Additional Resouces for `keras` Optimizers\n",
        "\n",
        "You can refer to [this tutorial](https://machinelearningknowledge.ai/keras-optimizers-explained-with-examples-for-beginners/) or [this article](https://towardsdatascience.com/a-quick-guide-to-neural-network-optimizers-with-applications-in-keras-e4635dd1cca4) or [this article](https://mlfromscratch.com/optimizers-explained/#/) for more information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVSEK93wfH12"
      },
      "source": [
        "## `keras` Activations\n",
        "\n",
        "- Activations, or activation functions, serve two goals in any NN:\n",
        "  - It serves as a gate function to control if a neuron is \"fired\" (ouputs a value of `1`) or not (ouputs a value of `0`)\n",
        "  - It serves as a transformation function to convert input data into the output data in a _different_ space\n",
        "\n",
        "- We can use both __linear__ and __non-linear__ activations in NN\n",
        "  - but we use much __more__ non-linear activations\n",
        "- Below is the comparison of activation between a brain neuron and a neuron in a NN:\n",
        "\n",
        "![activation process](https://machinelearningknowledge.ai/wp-content/uploads/2020/11/Activation_Function.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV4nBrz-kx1C"
      },
      "source": [
        "### Linear Activations\n",
        "\n",
        "- We have two types of linear activations:\n",
        "  - Step function: if the input is greater than a pre-defined threshold, the neuron is fired; otherwise it is not;\n",
        "  - Linear function: multiply the input data by a pre-defined constant ($ y = c \\times x $) - allows multiple outputs rather than just `0/1`.\n",
        "\n",
        "- We do not use linear activation anymore because:\n",
        "  - All hidden layers are collapsed into one --> so deep learning becomes shallow learning\n",
        "  - Not possible for backpropgation\n",
        "  - NN becomes interwined linear (regression) models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm_Wpu_imKRd"
      },
      "source": [
        "### Non-linear Activations in `keras`\n",
        "\n",
        "- Mainly we use the following types of __non-linear__ activations in NNs:\n",
        "  - Sigmoid/Logistic\n",
        "  - Tanh/Hyperbolic Tangent\n",
        "  - ReLU/Rectified Linear Unit\n",
        "  - Softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8jDJXjALUzY"
      },
      "source": [
        "### Sigmoid Activation\n",
        "\n",
        "- The `sigmoid` activation is widely used in __binary classification__ problems, usually used with the `binary-crossentropy` loss function when used in the __output__ layer\n",
        "- Mathematically, the `sigmoid` functions is defined by:\n",
        "\n",
        "$$ sigmoid(z) = \\frac{e^z}{e^z + 1} = \\frac{1}{1+e^{-z}}$$\n",
        "\n",
        "- And the `sigmoid` activation is illustrated by:\n",
        "\n",
        "![sigmoid](https://deeplizard.com/images/sigmoid%20function%20graph%20curve.svg)\n",
        "\n",
        "- `sigmoid` activation outputs between `0` and `1` and it is non-linear\n",
        "  - so it is good to output probabilities (normalized)\n",
        "  - and convert the input data into a non-linear space\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUufRiQQQLot"
      },
      "source": [
        "#### Pros and Cons of `sigmoid`\n",
        "\n",
        "- Pros:\n",
        "  - Avoid \"jumps\" in outputs, and yield _smooth_ gradients\n",
        "  - if the input value is big, then the prediction is clear\n",
        "- Cons:\n",
        "  - __Vanishing gradients!!!__ for very high/low input values, the backpropgation returns __very low__ updates to the parameters because the gradients are low.\n",
        "  - Outputs are not zero-centered, and it is computationally expensive.\n",
        "\n",
        "![vanishing gradient](https://miro.medium.com/max/1260/1*iOAQr-iRgHoVpFNSWYV8Iw.png)\n",
        "\n",
        "- So recently the `tanh` activation becomes more popular."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5R7dYV8Q-n8"
      },
      "source": [
        "### TanH Activation\n",
        "\n",
        "- The `tanh` activation is also __non-linear__ and __differentiable__.\n",
        "  - Shape is similar to `sigmoid`\n",
        "![tanh](https://miro.medium.com/max/925/1*TLcyVwbgfrNm3XCWW4rFzg.png)\n",
        "- The output is in the (-1, 1) range\n",
        "  - Not great for the output layers since the output is not in the (0,1) range as the `sigmoid` activation, but good for the __hidden__ layers\n",
        "  - The max derivative is `1` so it is good for backpropgation\n",
        "    - we can fully transform the errors to previous layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cja9VbeVSNbr"
      },
      "source": [
        "#### Pros and Cons of `tanh`\n",
        "\n",
        "- Pros\n",
        "  - Zero-centered: if the sign (`+/-`) in the input data have strong meanings, `tanh` is very sensitive\n",
        "- Cons\n",
        "  - Less susceptible to the vanishing gradient, otherwise like `sigmoid`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6y8g97cSy5U"
      },
      "source": [
        "### ReLU Activation\n",
        "\n",
        "- Both `sigmoid` and `tanh` are computationally expensive, for most of the classification problem, we can use the `relu` activation in the __hidden__ layers\n",
        "  - We do not use it in the __output__ layers\n",
        "  - The `relu` activation is given by:\n",
        "  $$ relu(x) = max(0, x) $$\n",
        "  - The `relu` activation looks like below:\n",
        "\n",
        "![relu](https://miro.medium.com/max/922/1*yDTcsgBV3pcUvXFVwE8kZQ.png)\n",
        "\n",
        "- The output of `relu` ranges in $ (0, +\\infty) $, but it is not differentiable at $0$.\n",
        "- The grsdient is always $1$, so we can pass the maximal amount of the error throughout the NN via back-propagation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zguj0cL_UAm6"
      },
      "source": [
        "#### Pros and Cons of `relu`\n",
        "\n",
        "- Pros\n",
        "  - `relu` is computationally efficient - quick converge of the network\n",
        "  - `relu` is a non-linear function although it does not appear that way\n",
        "- Cons\n",
        "  - If the input data contains a lot of **zeros** and **negatives**, the network cannot back-propagate since gradient of `relu` is zero (**dying relu**)\n",
        "\n",
        "- That's why we use something like `leaky-relu`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlGYXUmKVBt2"
      },
      "source": [
        "### Leaky ReLU Activation\n",
        "\n",
        "- The only reason we use `leaky_relu` is to deal with the __dying relu__ problem\n",
        "  - `leaky_relu` has a positive slope (gradient) in the negative-zero area, so it is differentiable - BP enabled!!\n",
        "  - `leaky_relu` is given by below:\n",
        "  $$ leakyReLU(x) = max(0.1 \\times x, x) $$\n",
        "  - `leaky_relu` looks like below:\n",
        "\n",
        "![leakyrelu](https://www.researchgate.net/profile/Stefano-Romanazzi/publication/325226633/figure/fig9/AS:627667623768071@1526659031098/Plot-of-the-LeakyReLU-function.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HVjRYCCWPiq"
      },
      "source": [
        "### Softmax Activation\n",
        "\n",
        "- `softmax` is a vector extension to `sigmoid`\n",
        "- `softmax` takes a vector of real values and convert each of them into corresponding probabilities.\n",
        "- in a $C$-class classification, where $ k \\in [1, 2, ..., C] $, the probability of each class $k$ is given by:\n",
        "\n",
        "$$ p(y=k|x) = \\frac{e^{z(x)_k}}{\\sum_{j=1}^C{e^{z(x)_j}}}$$\n",
        "\n",
        "- if $C=2$, `softmax` is the same as `sigmoid`\n",
        "  - so we can use `softmax` for __multi-class classification__ problems, in conjunction with CCE.\n",
        "\n",
        "__PRO TIP__: we can use `softmax` for __binary classification__ problems, and we should use `binary-crossentropy` loss function with it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBFIzo-bYu6X"
      },
      "source": [
        "### Additional Resources for `keras` Activations\n",
        "\n",
        "Refer to [this article](https://towardsdatascience.com/exploring-activation-functions-for-neural-networks-73498da59b02) or [this post](https://missinglink.ai/guides/neural-network-concepts/7-types-neural-network-activation-functions-right/) or [this article](http://web.stanford.edu/~nanbhas//blog/sigmoid-softmax.html) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hGIIoAdZCp5"
      },
      "source": [
        "## Regularization\n",
        "\n",
        "- Generally in ML, we use regularizations to avoid the __overfitting__ problem.\n",
        "- Typically we use three types of regularizations in `keras`, namely:\n",
        "  - DropOut\n",
        "  - Early Stopping\n",
        "  - L1/L2 Regularization, aka. weight decay\n",
        "  \n",
        "__PRO TIP1__: You should always consider using `dropout` in your NNs.\n",
        "\n",
        "__PRO TIP2__: Early Stopping allows you to select a large number of epoch without worrying about overfitting.\n",
        "\n",
        "- And if there is no other way to improve the results, you can consider using weight decay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPjqEHRTaS4D"
      },
      "source": [
        "#### Dropout Examples\n",
        "\n",
        "- For instance, we use the following `mnist` example to show the value of `dropout`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "22vMjp3HeUL5",
        "outputId": "1a7833c4-22b7-454b-fb6b-6aacd56ef152"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from matplotlib import pyplot as plt\n",
        "plt.style.use('dark_background')\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
        "from tensorflow.keras.utils import normalize, to_categorical\n",
        "\n",
        "#### load the data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "plt.imshow(X_train[0], cmap = plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBwtOuGPat_-"
      },
      "source": [
        "#### Preprocessing - normalization and OHE\n",
        "\n",
        "X_train = normalize(X_train, axis=1)\n",
        "X_test = normalize(X_test, axis=1)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFRuu-Ada4bB",
        "outputId": "4ef4cf3f-e00e-4e88-805a-f08a3368c015"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3X7peXya6RZ"
      },
      "source": [
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyWmr_r4a8ph",
        "outputId": "e50f2385-963c-4f30-8c3f-9110b6a41c0d"
      },
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.7325 - accuracy: 0.7985 - val_loss: 0.1663 - val_accuracy: 0.9523\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1718 - accuracy: 0.9503 - val_loss: 0.1318 - val_accuracy: 0.9615\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 1s 4ms/step - loss: 0.1179 - accuracy: 0.9652 - val_loss: 0.1035 - val_accuracy: 0.9720\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0862 - accuracy: 0.9733 - val_loss: 0.0907 - val_accuracy: 0.9732\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 0.9803 - val_loss: 0.0879 - val_accuracy: 0.9757\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0510 - accuracy: 0.9849 - val_loss: 0.0802 - val_accuracy: 0.9773\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0421 - accuracy: 0.9880 - val_loss: 0.0822 - val_accuracy: 0.9780\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0306 - accuracy: 0.9916 - val_loss: 0.0774 - val_accuracy: 0.9773\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 1s 3ms/step - loss: 0.0269 - accuracy: 0.9921 - val_loss: 0.0843 - val_accuracy: 0.9778\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 1s 4ms/step - loss: 0.0216 - accuracy: 0.9939 - val_loss: 0.0894 - val_accuracy: 0.9755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "40aGWVcEa_Mx",
        "outputId": "b1e1e26e-0e58-4c8e-e851-37aebf9d8bea"
      },
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sTeL9yXbGGL"
      },
      "source": [
        "As you can see above, without `dropout`, the validation loss stops decreasing around epoch `3` - which means after that the model starts __overfitting__.\n",
        "\n",
        "Now we can start adding the `Dropout` layers into the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xGNHKZdbExy",
        "outputId": "c58937c4-cdf2-4115-8fdc-c25b1faee955"
      },
      "source": [
        "model_dropout = Sequential()\n",
        "model_dropout.add(Flatten(input_shape=(28, 28)))\n",
        "model_dropout.add(Dense(128))\n",
        "#### 0.5 means we random throw out 50% of the weights learnt\n",
        "#### so that the model training is more difficult\n",
        "#### hence it is harder to overfit the model\n",
        "model_dropout.add(Dropout(0.5))\n",
        "model_dropout.add(Activation('relu'))\n",
        "model_dropout.add(Dense(128))\n",
        "model_dropout.add(Dropout(0.5))\n",
        "model_dropout.add(Activation('relu'))\n",
        "model_dropout.add(Dense(10))\n",
        "model_dropout.add(Activation('softmax'))\n",
        "model_dropout.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9b6n5AGbsYH"
      },
      "source": [
        "model_dropout.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2stLqa44b8kI",
        "outputId": "a568a95d-2009-49f0-8245-207377b5b094"
      },
      "source": [
        "history_dropout = model_dropout.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2217 - accuracy: 0.9371 - val_loss: 0.1097 - val_accuracy: 0.9680\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2017 - accuracy: 0.9417 - val_loss: 0.1032 - val_accuracy: 0.9712\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1905 - accuracy: 0.9448 - val_loss: 0.0984 - val_accuracy: 0.9695\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1803 - accuracy: 0.9477 - val_loss: 0.0941 - val_accuracy: 0.9727\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1722 - accuracy: 0.9492 - val_loss: 0.0921 - val_accuracy: 0.9732\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1616 - accuracy: 0.9518 - val_loss: 0.0883 - val_accuracy: 0.9747\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1551 - accuracy: 0.9547 - val_loss: 0.0868 - val_accuracy: 0.9753\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1477 - accuracy: 0.9559 - val_loss: 0.0858 - val_accuracy: 0.9747\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1409 - accuracy: 0.9572 - val_loss: 0.0898 - val_accuracy: 0.9740\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1415 - accuracy: 0.9585 - val_loss: 0.0812 - val_accuracy: 0.9760\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "m-LnKznMb-Mh",
        "outputId": "287b21ff-d34b-4f8d-e9f6-fa295fb1b078"
      },
      "source": [
        "#### plot the training history again\n",
        "loss = history_dropout.history['loss']\n",
        "val_loss = history_dropout.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdPQSA9acRtN"
      },
      "source": [
        "We can observe that with the help of the `Dropout` layers, the validation loss keeps decreasing even at epoch 10. Thus, we successfully fought the overfitting problem.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDu8p2W1g7iC"
      },
      "source": [
        "### Early Stopping\n",
        "\n",
        "- But we may think of: how about we select a large number of epochs, so that we can reach the __best__ performance of our model? Sure we can.  \n",
        "- But in the meanwhile, if we increase the number of epochs too much, we may run into the overfitting problem again, even with the `Dropout` layers.\n",
        "- So we can use __early stopping__.\n",
        "\n",
        "- The idea behind __early stopping__ is straightforward.\n",
        "  - We have `keras` monitor the selected metric(s) (e.g., validation loss),\n",
        "  - if it stop change in the desired direction (e.g., decreasing), we stop the training process.\n",
        "  - Sicne the training process does not complete, it is an __early__ stop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkS6Lu6EcK4S",
        "outputId": "bbcdcbeb-bd4d-4e46-8162-4ac72fa23240"
      },
      "source": [
        "model_es = Sequential()\n",
        "model_es.add(Flatten(input_shape=(28, 28)))\n",
        "model_es.add(Dense(128))\n",
        "model_es.add(Dropout(0.5))\n",
        "model_es.add(Activation('relu'))\n",
        "model_es.add(Dense(128))\n",
        "model_es.add(Dropout(0.5))\n",
        "model_es.add(Activation('relu'))\n",
        "model_es.add(Dense(10))\n",
        "model_es.add(Activation('softmax'))\n",
        "model_es.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWNphHJmfJWp"
      },
      "source": [
        "model_es.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxlw2I4UeXvs"
      },
      "source": [
        "#### simple early stopping\n",
        "from keras.callbacks import EarlyStopping\n",
        "#### we specify to monitor validation loss\n",
        "#### `min` means if `val_loss` stops decreasing\n",
        "#### and `patience` means number of epochs after `val_loss` stops decreasing\n",
        "#### we use `patience` to avoid stopping training at local minima\n",
        "#### particularly when use in combination with `Dropout`\n",
        "#### you shoud definitely use `patience`\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTERgaoofUXD",
        "outputId": "a6f357a8-7cbf-4cb1-9f76-e0efdb37690f"
      },
      "source": [
        "#### now we can try 100 epochs\n",
        "\n",
        "history_es = model_es.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True,\n",
        "    callbacks=[es]\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2656 - accuracy: 0.9236 - val_loss: 0.1221 - val_accuracy: 0.9647\n",
            "Epoch 2/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2332 - accuracy: 0.9330 - val_loss: 0.1111 - val_accuracy: 0.9677\n",
            "Epoch 3/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2128 - accuracy: 0.9391 - val_loss: 0.1033 - val_accuracy: 0.9698\n",
            "Epoch 4/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1964 - accuracy: 0.9428 - val_loss: 0.0941 - val_accuracy: 0.9720\n",
            "Epoch 5/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1846 - accuracy: 0.9454 - val_loss: 0.0918 - val_accuracy: 0.9725\n",
            "Epoch 6/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1715 - accuracy: 0.9488 - val_loss: 0.0881 - val_accuracy: 0.9752\n",
            "Epoch 7/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1616 - accuracy: 0.9526 - val_loss: 0.0873 - val_accuracy: 0.9745\n",
            "Epoch 8/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1551 - accuracy: 0.9534 - val_loss: 0.0877 - val_accuracy: 0.9755\n",
            "Epoch 9/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1488 - accuracy: 0.9551 - val_loss: 0.0819 - val_accuracy: 0.9773\n",
            "Epoch 10/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1392 - accuracy: 0.9584 - val_loss: 0.0837 - val_accuracy: 0.9767\n",
            "Epoch 11/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1361 - accuracy: 0.9593 - val_loss: 0.0812 - val_accuracy: 0.9773\n",
            "Epoch 12/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1345 - accuracy: 0.9589 - val_loss: 0.0852 - val_accuracy: 0.9750\n",
            "Epoch 13/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1274 - accuracy: 0.9618 - val_loss: 0.0759 - val_accuracy: 0.9793\n",
            "Epoch 14/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1228 - accuracy: 0.9622 - val_loss: 0.0766 - val_accuracy: 0.9785\n",
            "Epoch 15/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1168 - accuracy: 0.9636 - val_loss: 0.0768 - val_accuracy: 0.9793\n",
            "Epoch 16/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1158 - accuracy: 0.9656 - val_loss: 0.0766 - val_accuracy: 0.9783\n",
            "Epoch 17/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1162 - accuracy: 0.9648 - val_loss: 0.0751 - val_accuracy: 0.9788\n",
            "Epoch 18/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1144 - accuracy: 0.9656 - val_loss: 0.0725 - val_accuracy: 0.9800\n",
            "Epoch 19/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1114 - accuracy: 0.9661 - val_loss: 0.0779 - val_accuracy: 0.9777\n",
            "Epoch 20/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1109 - accuracy: 0.9660 - val_loss: 0.0764 - val_accuracy: 0.9790\n",
            "Epoch 21/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1077 - accuracy: 0.9666 - val_loss: 0.0771 - val_accuracy: 0.9780\n",
            "Epoch 22/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1042 - accuracy: 0.9674 - val_loss: 0.0723 - val_accuracy: 0.9795\n",
            "Epoch 23/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1044 - accuracy: 0.9681 - val_loss: 0.0729 - val_accuracy: 0.9810\n",
            "Epoch 24/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1000 - accuracy: 0.9692 - val_loss: 0.0729 - val_accuracy: 0.9805\n",
            "Epoch 25/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1007 - accuracy: 0.9688 - val_loss: 0.0740 - val_accuracy: 0.9803\n",
            "Epoch 26/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1002 - accuracy: 0.9683 - val_loss: 0.0760 - val_accuracy: 0.9790\n",
            "Epoch 27/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0955 - accuracy: 0.9700 - val_loss: 0.0754 - val_accuracy: 0.9785\n",
            "Epoch 00027: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsUkuDYRf4S5"
      },
      "source": [
        "Notice `val_loss` start increasing after epoch 22? `keras` continued to train `model_es` for 5 epochs (epoch 27), but the best model state at epoch 22 is saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "XrILZ42QfdOs",
        "outputId": "cbe9d1ea-faa1-4256-b5b6-502ab50931bf"
      },
      "source": [
        "#### plot the training history again\n",
        "loss = history_es.history['loss']\n",
        "val_loss = history_es.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7ghHL0Qgbbb"
      },
      "source": [
        "### Weight Decay\n",
        "\n",
        "- Additionally, we can use weight decay to restrain the model from overfitting.\n",
        "- There are three types of weight decay in `keras`:\n",
        "  - l1: Activity is calculated as the sum of absolute values.\n",
        "  - l2: Activity is calculated as the sum of the squared values.\n",
        "  - l1_l2: Activity is calculated as the sum of absolute and sum of the squared values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHdbzCp3gQbC",
        "outputId": "04a4d820-5ea5-4817-81ba-5b8a10621521"
      },
      "source": [
        "# import regularizer\n",
        "from keras.regularizers import l1, l2, l1_l2\n",
        "\n",
        "model_l1 = Sequential()\n",
        "model_l1.add(Flatten(input_shape=(28, 28)))\n",
        "model_l1.add(Dense(128, activation='relu', activity_regularizer=l1(0.001)))\n",
        "model_l1.add(Dropout(0.5))\n",
        "model_l1.add(Dense(128, activation='relu', activity_regularizer=l1(0.001)))\n",
        "model_l1.add(Dropout(0.5))\n",
        "model_l1.add(Dense(10))\n",
        "model_l1.add(Activation('softmax'))\n",
        "model_l1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_4 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 10)                1290      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 118,282\n",
            "Trainable params: 118,282\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2Wrt1EVhlv0"
      },
      "source": [
        "model_l1.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vUmpDKphpnV",
        "outputId": "c6f1b4c1-447f-477b-eabb-36e8279d1ca8"
      },
      "source": [
        "history_l1 = model_l1.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1,\n",
        "    verbose = 1,\n",
        "    shuffle=True,\n",
        "    callbacks=[es]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "422/422 [==============================] - 3s 5ms/step - loss: 1.1784 - accuracy: 0.6380 - val_loss: 0.2662 - val_accuracy: 0.9405\n",
            "Epoch 2/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4138 - accuracy: 0.8993 - val_loss: 0.2033 - val_accuracy: 0.9585\n",
            "Epoch 3/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3328 - accuracy: 0.9215 - val_loss: 0.1770 - val_accuracy: 0.9643\n",
            "Epoch 4/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2950 - accuracy: 0.9305 - val_loss: 0.1625 - val_accuracy: 0.9690\n",
            "Epoch 5/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2620 - accuracy: 0.9387 - val_loss: 0.1473 - val_accuracy: 0.9705\n",
            "Epoch 6/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2431 - accuracy: 0.9437 - val_loss: 0.1417 - val_accuracy: 0.9728\n",
            "Epoch 7/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2242 - accuracy: 0.9471 - val_loss: 0.1369 - val_accuracy: 0.9740\n",
            "Epoch 8/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2126 - accuracy: 0.9513 - val_loss: 0.1293 - val_accuracy: 0.9747\n",
            "Epoch 9/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2020 - accuracy: 0.9521 - val_loss: 0.1276 - val_accuracy: 0.9738\n",
            "Epoch 10/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1956 - accuracy: 0.9537 - val_loss: 0.1220 - val_accuracy: 0.9763\n",
            "Epoch 11/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1871 - accuracy: 0.9580 - val_loss: 0.1225 - val_accuracy: 0.9752\n",
            "Epoch 12/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1791 - accuracy: 0.9575 - val_loss: 0.1181 - val_accuracy: 0.9750\n",
            "Epoch 13/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1722 - accuracy: 0.9607 - val_loss: 0.1178 - val_accuracy: 0.9753\n",
            "Epoch 14/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1655 - accuracy: 0.9617 - val_loss: 0.1111 - val_accuracy: 0.9772\n",
            "Epoch 15/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1649 - accuracy: 0.9625 - val_loss: 0.1126 - val_accuracy: 0.9770\n",
            "Epoch 16/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1625 - accuracy: 0.9625 - val_loss: 0.1106 - val_accuracy: 0.9765\n",
            "Epoch 17/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1577 - accuracy: 0.9641 - val_loss: 0.1065 - val_accuracy: 0.9782\n",
            "Epoch 18/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1595 - accuracy: 0.9632 - val_loss: 0.1143 - val_accuracy: 0.9748\n",
            "Epoch 19/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1552 - accuracy: 0.9658 - val_loss: 0.1067 - val_accuracy: 0.9775\n",
            "Epoch 20/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1515 - accuracy: 0.9653 - val_loss: 0.1068 - val_accuracy: 0.9785\n",
            "Epoch 21/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1423 - accuracy: 0.9668 - val_loss: 0.1055 - val_accuracy: 0.9802\n",
            "Epoch 22/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1472 - accuracy: 0.9662 - val_loss: 0.1062 - val_accuracy: 0.9783\n",
            "Epoch 23/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1450 - accuracy: 0.9661 - val_loss: 0.1051 - val_accuracy: 0.9797\n",
            "Epoch 24/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1400 - accuracy: 0.9680 - val_loss: 0.1033 - val_accuracy: 0.9788\n",
            "Epoch 25/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1388 - accuracy: 0.9681 - val_loss: 0.1030 - val_accuracy: 0.9792\n",
            "Epoch 26/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1334 - accuracy: 0.9701 - val_loss: 0.1043 - val_accuracy: 0.9783\n",
            "Epoch 27/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1366 - accuracy: 0.9704 - val_loss: 0.1033 - val_accuracy: 0.9783\n",
            "Epoch 28/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1356 - accuracy: 0.9693 - val_loss: 0.1060 - val_accuracy: 0.9777\n",
            "Epoch 29/100\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1334 - accuracy: 0.9694 - val_loss: 0.1059 - val_accuracy: 0.9788\n",
            "Epoch 30/100\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1301 - accuracy: 0.9711 - val_loss: 0.1031 - val_accuracy: 0.9783\n",
            "Epoch 00030: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ede2uZf4h9bQ"
      },
      "source": [
        "We can observe that `model_l1` is trained for 30 epochs, although the model performance did not improve. So regularizations do not guarantee better performance, but we do get a better shot at __global optimum__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "nIA8iWKJht4N",
        "outputId": "afa69e04-0cd1-4878-a66a-f88044dd6938"
      },
      "source": [
        "#### plot the training history again\n",
        "loss = history_l1.history['loss']\n",
        "val_loss = history_l1.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytH8M0dciS1p"
      },
      "source": [
        "Judging by the figure above, we can see that the L1-regualrization makes the training curve __smoother__, which is desired.\n",
        "\n",
        "If you want to learn to how use other types of regularizations, or use regularizations in other types of NNs, refer to [this article](https://machinelearningmastery.com/how-to-reduce-generalization-error-in-deep-neural-networks-with-activity-regularization-in-keras/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSHhY4u9irJV"
      },
      "source": [
        "# Deep Learning & Artificial Intelligence\n",
        "## Neural Networks Building Blocks - Loss Functions, Optimizers, and Activations\n",
        "### Dr. Jie Tao, Fairfield University"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_5YZiibiQ3r"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}