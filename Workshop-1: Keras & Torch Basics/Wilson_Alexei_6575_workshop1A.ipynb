{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A Gentle Intro to `PyTorch` and tensors\n",
        "\n",
        "By Dr. Jie Tao\n",
        "\n",
        "ver.: 0.1"
      ],
      "metadata": {
        "id": "Gi0tUXtteT54"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have spent quite some time playing with `tensorflow`, however, another well-adopted package in terms of __deep learning__ is `PyTorch`, or just `torch` for short.\n",
        "\n",
        "Traditionally, `tensorflow` and `torch` have some different use cases:\n",
        "- `tf` is good for building your __own__ networks, particularly if the network topology (aka., architecture) is simple;\n",
        "- `torch` is good when the architecture is not that simple, so it was popular with __transfer learning__ (will be covered in __Week 4__);\n",
        "- `torch` also comes with good **operations** if you want to deal with tensors.\n",
        "\n",
        "But nowadays they function almost the same, usually you use one if you are, or your group is, more familiar with it over the other. So it is crucial if you understand how `torch` works, which is the purpose of this workshop."
      ],
      "metadata": {
        "id": "tRSJBszhen6b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mwMiyFpeRJU"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We typically add a block at the top of the notebook when using `torch` to determine if we want to use __GPU__ or not."
      ],
      "metadata": {
        "id": "QLShnOPbgX8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\") ## you can specify which GPU to use if you have more than one, for intance `cuda:0` is the first GPU\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "TbNqgcPqf7lk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "826c9652-992b-4b2a-8f2f-d9ebd5499490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5wv_Wkwfgcnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors and Tensor Operations\n",
        "\n",
        "Tensors are the basic unit in deep learning, which is the fundamental data structure in `torch`.\n",
        "\n",
        "Tensors can be created from almost any collection objects in Python, for instance `lists` and `NumPy` arrays."
      ],
      "metadata": {
        "id": "EuhXeU1yguEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_lst = [1, 2, 3, 4, 5, 6] ## make sure the list only contains ONE data type\n",
        "lst_tensor = torch.tensor(my_lst)\n",
        "lst_tensor"
      ],
      "metadata": {
        "id": "HU-VYUtJgo3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65924657-7273-4f54-fe90-f25ff127d1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting tensor back to list is not as straightforward, for instance, below code doesn't work as expected."
      ],
      "metadata": {
        "id": "l9x-2_KyhzJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(lst_tensor)"
      ],
      "metadata": {
        "id": "7OIndDC0hqNR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c978b569-9681-4225-bd11-cafa1e3d3e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(1), tensor(2), tensor(3), tensor(4), tensor(5), tensor(6)]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## but this method works!!\n",
        "lst_tensor.tolist()"
      ],
      "metadata": {
        "id": "O5eQi8K9hwd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956adbac-c8dc-40fb-c635-ffa06f2febb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arrays are more flexible."
      ],
      "metadata": {
        "id": "eV-5De_UiFtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from datetime import date"
      ],
      "metadata": {
        "id": "F0QOwfy-h_A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get current year\n",
        "year = date.today().year"
      ],
      "metadata": {
        "id": "_qb0QPZwieRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(year) ## make sure the array is replicable\n",
        "my_arr = np.random.rand(10, 10)\n",
        "my_arr"
      ],
      "metadata": {
        "id": "zLjdtzlxiQV2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02401477-4432-4612-8736-410246e8ffe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3219883 , 0.89042245, 0.58805226, 0.12659609, 0.14134122,\n",
              "        0.46789559, 0.02208966, 0.72727471, 0.52438734, 0.54493524],\n",
              "       [0.45637326, 0.50138226, 0.39446855, 0.1511723 , 0.36087518,\n",
              "        0.16207701, 0.33795869, 0.18032328, 0.3909914 , 0.03564821],\n",
              "       [0.56486165, 0.20346149, 0.32060446, 0.37656378, 0.18405414,\n",
              "        0.10395184, 0.45492722, 0.19586384, 0.37852542, 0.93053196],\n",
              "       [0.76015971, 0.77076424, 0.59670056, 0.79162115, 0.8103383 ,\n",
              "        0.98055723, 0.88478525, 0.10980113, 0.81971076, 0.30761289],\n",
              "       [0.26149467, 0.40572354, 0.55342038, 0.62552644, 0.07876025,\n",
              "        0.97228343, 0.41131105, 0.7216644 , 0.66328748, 0.21822526],\n",
              "       [0.18717254, 0.72977924, 0.86331326, 0.39172036, 0.11004811,\n",
              "        0.9127915 , 0.35700599, 0.41296218, 0.18354969, 0.58599027],\n",
              "       [0.85567085, 0.78968122, 0.08784242, 0.93299327, 0.49995114,\n",
              "        0.36425699, 0.48360619, 0.51522459, 0.99464347, 0.75340344],\n",
              "       [0.36581992, 0.61137308, 0.41961135, 0.09167672, 0.53485392,\n",
              "        0.34076422, 0.01834099, 0.60345262, 0.92180617, 0.28136413],\n",
              "       [0.83480098, 0.54962266, 0.02179102, 0.34705989, 0.55003479,\n",
              "        0.01320563, 0.71589271, 0.18977701, 0.74246707, 0.62943137],\n",
              "       [0.36218393, 0.62702939, 0.51488475, 0.89490732, 0.51866543,\n",
              "        0.60740918, 0.474816  , 0.7095907 , 0.11524271, 0.73279407]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_arr.shape # (10, 10)"
      ],
      "metadata": {
        "id": "96zE8NgJiq3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f1afb5-209d-408e-b7d4-47a19b4aa0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr_tensor = torch.tensor(my_arr)\n",
        "type(arr_tensor) # torch.Tensor"
      ],
      "metadata": {
        "id": "27529XFHjMs6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "039d4037-00b9-46d1-dbac-27953f5ec2ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr_tensor.numpy() ### arr_tensor.detach().cpu().numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdPeruITakGK",
        "outputId": "4831f2d9-cd54-4896-d340-4c4c3ef02119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.3219883 , 0.89042245, 0.58805226, 0.12659609, 0.14134122,\n",
              "        0.46789559, 0.02208966, 0.72727471, 0.52438734, 0.54493524],\n",
              "       [0.45637326, 0.50138226, 0.39446855, 0.1511723 , 0.36087518,\n",
              "        0.16207701, 0.33795869, 0.18032328, 0.3909914 , 0.03564821],\n",
              "       [0.56486165, 0.20346149, 0.32060446, 0.37656378, 0.18405414,\n",
              "        0.10395184, 0.45492722, 0.19586384, 0.37852542, 0.93053196],\n",
              "       [0.76015971, 0.77076424, 0.59670056, 0.79162115, 0.8103383 ,\n",
              "        0.98055723, 0.88478525, 0.10980113, 0.81971076, 0.30761289],\n",
              "       [0.26149467, 0.40572354, 0.55342038, 0.62552644, 0.07876025,\n",
              "        0.97228343, 0.41131105, 0.7216644 , 0.66328748, 0.21822526],\n",
              "       [0.18717254, 0.72977924, 0.86331326, 0.39172036, 0.11004811,\n",
              "        0.9127915 , 0.35700599, 0.41296218, 0.18354969, 0.58599027],\n",
              "       [0.85567085, 0.78968122, 0.08784242, 0.93299327, 0.49995114,\n",
              "        0.36425699, 0.48360619, 0.51522459, 0.99464347, 0.75340344],\n",
              "       [0.36581992, 0.61137308, 0.41961135, 0.09167672, 0.53485392,\n",
              "        0.34076422, 0.01834099, 0.60345262, 0.92180617, 0.28136413],\n",
              "       [0.83480098, 0.54962266, 0.02179102, 0.34705989, 0.55003479,\n",
              "        0.01320563, 0.71589271, 0.18977701, 0.74246707, 0.62943137],\n",
              "       [0.36218393, 0.62702939, 0.51488475, 0.89490732, 0.51866543,\n",
              "        0.60740918, 0.474816  , 0.7095907 , 0.11524271, 0.73279407]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first operation we often use is `mean`. Similar to `NumPy` we can get the mean along any dimensions.\n",
        "\n",
        "Similarly you can do `max` or `min` or `std`."
      ],
      "metadata": {
        "id": "YOApXPB0jD7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## mean of whole matrix\n",
        "torch.mean(arr_tensor) # 0d-tensor, one scalar number"
      ],
      "metadata": {
        "id": "c9RiPzdXi7JV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c615fd2b-6ec8-4a66-e6c8-08ee88b93595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4814, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## mean along dimension of 0 - rows\n",
        "torch.mean(arr_tensor, dim=0)"
      ],
      "metadata": {
        "id": "Plua87QqjcSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a5aa24d-72e4-4f23-f4df-93a3aeb4e92e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4971, 0.6079, 0.4361, 0.4730, 0.3789, 0.4925, 0.4161, 0.4366, 0.5735,\n",
              "        0.5020], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## mean along dimension of 1 - cols\n",
        "torch.mean(arr_tensor, dim=1)"
      ],
      "metadata": {
        "id": "o2LGUMcwjqrX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3206fb70-051f-47f6-da29-6d2cca795cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4355, 0.2971, 0.3713, 0.6832, 0.4912, 0.4734, 0.6277, 0.4189, 0.4594,\n",
              "        0.5558], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__PRO TIP__: why do we want to do these things in `torch` rather than `NumPy`? Since we can use the __GPU__. If your data is big then the calculation is day and night."
      ],
      "metadata": {
        "id": "St6OCVddqZe7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%timeit\n",
        "# for i in range(100):\n",
        "#   embs = torch.tensor(np.random.rand(1000, 256, 768)).to(device) ## .to(\"cuda\")/.to(\"cpu\")\n",
        "#   res = torch.mean(embs, dim=1)"
      ],
      "metadata": {
        "id": "0QWt1yObqo9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%timeit\n",
        "# for i in range(100):\n",
        "#   res = np.mean(np.random.rand(1000, 256, 768), axis=1)"
      ],
      "metadata": {
        "id": "f0W7V1hcrmye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another operation we always use is `stack`. For instance, if you have a list of 1D tensors, you can stack them into a 2D tensor.\n",
        "\n",
        "__Note__: `torch` requires the tensors to be stacked to have the same shape along the dimension to be stacked. Use the 1D tensor example, all tensors should have the same length (shape at dim `0`)."
      ],
      "metadata": {
        "id": "31k807Z3j_pL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# list(arr_tensor) makes a list of 10 1D tensors, each with the length of 10\n",
        "\n",
        "torch.stack(list(arr_tensor)).shape # (10, 10)"
      ],
      "metadata": {
        "id": "4pl_7RbKjuHJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c26e6374-7fee-40bf-aa25-acc5273bc6c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since they are 1D tensors, you can use the default `dim=0` argument with stack, if it's not the case, make sure you change it."
      ],
      "metadata": {
        "id": "6k7RXTq0lCJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack(list(arr_tensor), dim=1) ## is the transpose of the 2D tensor above"
      ],
      "metadata": {
        "id": "fmYDmym2kq57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb93d86d-a7b4-4ded-a3e6-c2a66b2654a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3220, 0.4564, 0.5649, 0.7602, 0.2615, 0.1872, 0.8557, 0.3658, 0.8348,\n",
              "         0.3622],\n",
              "        [0.8904, 0.5014, 0.2035, 0.7708, 0.4057, 0.7298, 0.7897, 0.6114, 0.5496,\n",
              "         0.6270],\n",
              "        [0.5881, 0.3945, 0.3206, 0.5967, 0.5534, 0.8633, 0.0878, 0.4196, 0.0218,\n",
              "         0.5149],\n",
              "        [0.1266, 0.1512, 0.3766, 0.7916, 0.6255, 0.3917, 0.9330, 0.0917, 0.3471,\n",
              "         0.8949],\n",
              "        [0.1413, 0.3609, 0.1841, 0.8103, 0.0788, 0.1100, 0.5000, 0.5349, 0.5500,\n",
              "         0.5187],\n",
              "        [0.4679, 0.1621, 0.1040, 0.9806, 0.9723, 0.9128, 0.3643, 0.3408, 0.0132,\n",
              "         0.6074],\n",
              "        [0.0221, 0.3380, 0.4549, 0.8848, 0.4113, 0.3570, 0.4836, 0.0183, 0.7159,\n",
              "         0.4748],\n",
              "        [0.7273, 0.1803, 0.1959, 0.1098, 0.7217, 0.4130, 0.5152, 0.6035, 0.1898,\n",
              "         0.7096],\n",
              "        [0.5244, 0.3910, 0.3785, 0.8197, 0.6633, 0.1835, 0.9946, 0.9218, 0.7425,\n",
              "         0.1152],\n",
              "        [0.5449, 0.0356, 0.9305, 0.3076, 0.2182, 0.5860, 0.7534, 0.2814, 0.6294,\n",
              "         0.7328]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.equal(torch.stack(list(arr_tensor)).T, torch.stack(list(arr_tensor), dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8z-hLGClIjm",
        "outputId": "6e09ac0a-4d45-402b-83db-62d6a44134b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another similar operation we use is `cat` (short for concatennate). If we concatenate a list of 10 1D tensors of length 10, we get a 1D tensor of (1,100)."
      ],
      "metadata": {
        "id": "vJM-TVzZlsxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(list(arr_tensor)).shape # 100, or (1,100) can also use arr_tensor.flatten()"
      ],
      "metadata": {
        "id": "7AmxU1KalbRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a4dbad-b87e-4566-864a-2e49be405227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Note__: make sure you know what shape you want your tensor in, before you choose between `stack` and `cat`."
      ],
      "metadata": {
        "id": "mBIL4Y5mmHm2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1:\n",
        "\n",
        "Complete the following tasks."
      ],
      "metadata": {
        "id": "acp7cyCdmZnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_2d_arrays = [torch.tensor(np.random.rand(3,2)) for i in range(3)]\n",
        "len(my_2d_arrays), my_2d_arrays[0].shape # 3 and (3,2)"
      ],
      "metadata": {
        "id": "GgftGrPgl3pS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095ad907-53ac-4ec2-ffd8-b9b42d7166e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__TASK 1__: use proper operation to result a tensor with the shape of (9,2)."
      ],
      "metadata": {
        "id": "104uMVy1nL-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat(my_2d_arrays).shape"
      ],
      "metadata": {
        "id": "DBeLZSPEmsLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd26bb40-e294-4f08-cb7a-67b97513e47a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([9, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__TASK 2__: use proper operation to result a tensor with the shape of (3,3,2)."
      ],
      "metadata": {
        "id": "HhnDV5InnXHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack(my_2d_arrays).shape"
      ],
      "metadata": {
        "id": "FelvhT6inCPx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ac7cf8-465d-415d-cdfb-5c8ef82c6d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__TASK 3__: calculate the means of each of the 3 original tensors, along the dimension of 1.\n",
        "\n",
        "__HINT__: your result should have a shape of `(3,2)`.\n",
        "\n",
        "__Challenge__: do it in one line."
      ],
      "metadata": {
        "id": "3P47oAAJoGbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack([torch.mean(t, dim=0) for t in my_2d_arrays])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTMAqhu9iamH",
        "outputId": "1c7682bb-cafb-48de-99a5-d1c97a625710"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8434, 0.4399],\n",
              "        [0.5154, 0.4258],\n",
              "        [0.5393, 0.6311]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(torch.stack(my_2d_arrays), dim=1)"
      ],
      "metadata": {
        "id": "lWjCk2OvoBaz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25fd61d7-dae8-4f78-f841-435aeab49496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.8434, 0.4399],\n",
              "        [0.5154, 0.4258],\n",
              "        [0.5393, 0.6311]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next group of operations has to do with the shape of the tensors.\n",
        "\n",
        "The first one is our old friend `.reshape()`, just make sure the new shape is compatible with the old one."
      ],
      "metadata": {
        "id": "AtjkrYxjpvbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr_tensor.reshape(2,50)"
      ],
      "metadata": {
        "id": "Wl4YaFbCokmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46db9d03-0745-40f4-b45c-1a5927f1d914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3220, 0.8904, 0.5881, 0.1266, 0.1413, 0.4679, 0.0221, 0.7273, 0.5244,\n",
              "         0.5449, 0.4564, 0.5014, 0.3945, 0.1512, 0.3609, 0.1621, 0.3380, 0.1803,\n",
              "         0.3910, 0.0356, 0.5649, 0.2035, 0.3206, 0.3766, 0.1841, 0.1040, 0.4549,\n",
              "         0.1959, 0.3785, 0.9305, 0.7602, 0.7708, 0.5967, 0.7916, 0.8103, 0.9806,\n",
              "         0.8848, 0.1098, 0.8197, 0.3076, 0.2615, 0.4057, 0.5534, 0.6255, 0.0788,\n",
              "         0.9723, 0.4113, 0.7217, 0.6633, 0.2182],\n",
              "        [0.1872, 0.7298, 0.8633, 0.3917, 0.1100, 0.9128, 0.3570, 0.4130, 0.1835,\n",
              "         0.5860, 0.8557, 0.7897, 0.0878, 0.9330, 0.5000, 0.3643, 0.4836, 0.5152,\n",
              "         0.9946, 0.7534, 0.3658, 0.6114, 0.4196, 0.0917, 0.5349, 0.3408, 0.0183,\n",
              "         0.6035, 0.9218, 0.2814, 0.8348, 0.5496, 0.0218, 0.3471, 0.5500, 0.0132,\n",
              "         0.7159, 0.1898, 0.7425, 0.6294, 0.3622, 0.6270, 0.5149, 0.8949, 0.5187,\n",
              "         0.6074, 0.4748, 0.7096, 0.1152, 0.7328]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use operations like `squeeze` and `unsequeeze`.\n",
        "\n",
        "- `squeeze` will remove any dimension that has the length of `1` in your tensor;\n",
        "- `unsqueeze` will add a dimension with the length of `1` in the indicated location."
      ],
      "metadata": {
        "id": "qkUDBlbvuiXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(2,1,3,1,2)\n",
        "x.size()"
      ],
      "metadata": {
        "id": "2oP46w83pprY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6d8bba-9a1d-47ce-f683-1e523194f63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.squeeze(x)\n",
        "y.size()"
      ],
      "metadata": {
        "id": "sr2cyZ-yup5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c7b8d3-0de8-4620-b525-78bab03c28c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.squeeze(x,0).shape # dim 0 doesn't have length of 1 so squeeze doesn't work"
      ],
      "metadata": {
        "id": "yXx1WRd2vTi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cff64b29-f6b0-42f3-a887-e7f24d5e68f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.squeeze(x,1).shape # dim 1 has length of 1 so squeeze worked"
      ],
      "metadata": {
        "id": "s_xTIMIwval6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "194e3a46-cbe4-4fba-b3ad-83f5c87dbb93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.squeeze(x,(1, 2, 3)).shape # dim 2 doesn't have length of 1 so squeeze doesn't work"
      ],
      "metadata": {
        "id": "RAsKgu2XvmMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "149f29a3-5e07-42df-f421-8eda758ab2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`unsqueeze` works the opposite."
      ],
      "metadata": {
        "id": "TMcl3q3owAHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.unsqueeze(y, 1).shape"
      ],
      "metadata": {
        "id": "5PSjceFbvvYK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0455dbcc-b2e6-44ac-996f-9e5e9be7ac89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.unsqueeze(y, 0).shape"
      ],
      "metadata": {
        "id": "_bv2gc8Tv_Hp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba55270-3009-427b-b70c-49e70799363a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.unsqueeze(y, (1, 3)) ## doesn't work, you can only unsqueeze one dim at a time"
      ],
      "metadata": {
        "id": "JCvZsFMTwHoi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "c806b144-dfb8-4c44-b757-f7044829c7fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-22caf8884950>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## doesn't work, you can only unsqueeze one dim at a time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unsqueeze(): argument 'dim' (position 2) must be int, not tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# but this will work\n",
        "torch.unsqueeze(torch.unsqueeze(y, 1), 3).shape"
      ],
      "metadata": {
        "id": "Cogf5rIWwQ0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c0bfbe-66cc-4208-924e-8f48fd758c07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.equal(torch.unsqueeze(torch.unsqueeze(y, 1), 3), x)"
      ],
      "metadata": {
        "id": "wC-b98cRWBge",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf4252aa-02d2-4c1e-f020-c3c94cad8593"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another set of tensor methods/attributes have to do with the __Shape__. Besides the `.shape` method, we can use the `.size()` method and the `.ndim` attribute."
      ],
      "metadata": {
        "id": "MoLE0ym5ZILY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## you can investigate the shape in some different ways\n",
        "torch.unsqueeze(torch.unsqueeze(y, 1), 3).size()"
      ],
      "metadata": {
        "id": "JNzt-37qWIXG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90440eb0-88e8-4435-f2f3-0aa102ea5700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 3, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## number of dimensions\n",
        "torch.unsqueeze(torch.unsqueeze(y, 1), 3).ndim"
      ],
      "metadata": {
        "id": "NpnP0dIrWk9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "311c3deb-69be-4209-c7e5-b17e3c88d3ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last group of tensor operations has to do with the gradients (and back propagation). `torch` provided a [very nice tutorial](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/ad7e62b138c384adac98888ce94ff659/autogradqs_tutorial.ipynb) for it.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Jp1Ffg8bgZ0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Torch `dataset` and `dataloader` Objects\n",
        "\n",
        "`torch` purposely decouple the data from the training process so the code can be less messy. The two main primitives are:\n",
        "- `dataset`: stores data samples (e.g., training, testing, validation). This supports both __pre-loaded__ and your __custom__ datasets.\n",
        "- `dataloader`: wraps an iterable around the `Dataset` to enable easy access to the samples."
      ],
      "metadata": {
        "id": "zlS5tLUBZ7iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset ## this is the dataset class/object\n",
        "from torchvision import datasets ## this include some pre-load datasets vision\n",
        "from torchvision.transforms import ToTensor ## this converts loaded data into tensors\n",
        "import matplotlib.pyplot as plt ## vision data, plotting is important"
      ],
      "metadata": {
        "id": "rHirE4flXwWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data using `dataset`\n",
        "\n",
        "If you want to load a pre-loaded dataset (e.g., `Fashion-MNIST`):"
      ],
      "metadata": {
        "id": "fXacwMsmbNtc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## The data comes in pre-split\n",
        "#### TRAINING\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # change this to the path of your data folder\n",
        "    train=True, # this controls if the set is train\n",
        "    download=True, # if the data does not exist, download it\n",
        "    transform=ToTensor() # transform the data into tensors\n",
        ")\n",
        "\n",
        "#### TESTING\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "kI6Jjy0objYF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3ba020-e06d-4751-8e0f-013a4c9ac015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 19860696.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 334665.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 6113148.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 6720285.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can index `Datasets` manually like a `list`: `training_data[index]`."
      ],
      "metadata": {
        "id": "srTXurOQcLSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "id": "GYIBkjDRnG54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[0]"
      ],
      "metadata": {
        "id": "rQWyj-7LcB08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc0987c-5838-468b-84cd-78ec24be0e9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualing data\n",
        "\n",
        "The sample contains two elements, the first element is the image (processed) and the second is its label (`9`). Using the meta data we can decode the label to the actual class. We use `matplotlib` to visualize some samples in our training data.\n",
        "\n",
        "Supposed we want to visualze the first 9 samples."
      ],
      "metadata": {
        "id": "Ftkrw8nwcg68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UjptznHicXK5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "09796155-75ee-4b16-dd76-7658faeebfdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What about my own data?\n",
        "\n",
        "__NOTE__: refer to [this](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#creating-a-custom-dataset-for-your-files) if you need to load your own data. Note that this assumes your labels are in a csv file in the format of `image_name: label`, and all the corresponding images are in __one__ folder.\n",
        "\n",
        "__PRO-TIP__: the common way is we store all image in one folder, but create sub-folders for each class. In that case, you do not have the labels file - need to write your own code to derive the labels."
      ],
      "metadata": {
        "id": "wPahxfCddEnW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing your data for training with `DataLoaders`\n",
        "\n",
        "The `Dataset` retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass __multiple__ samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing to speed up data retrieval.\n",
        "\n",
        "`DataLoader` is an iterable that abstracts this complexity for us in an easy API.\n",
        "\n",
        "In below examples, we load every 64 images as a batch.\n",
        "\n",
        "__PRO-TIP__:\n",
        "1. Typically we use the same batch size for training and testing data.\n",
        "2. batch size is determined by your memory size, or GPU memory. If you get the out-of-memory error, reduce batch size."
      ],
      "metadata": {
        "id": "cf56V-lCd9U3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "### capitalized variables are global - serve whole notebook\n",
        "BATCH_SIZE = 64\n",
        "## TEST_BATCH_SIZE = 1\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "metadata": {
        "id": "qO1rLU79c1Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you need to iterate through the dataloader (although we don't usually do this):"
      ],
      "metadata": {
        "id": "PaiJ3SfdfO4p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for batch_data, batch_label in train_dataloader:\n",
        "  # print(batch_data, len(batch_data))\n",
        "  print(batch_label, len(batch_label))\n",
        "  break"
      ],
      "metadata": {
        "id": "4MVLn7O0e3r9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a957d3-af53-4195-98ae-21bc9924ebae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([8, 9, 8, 0, 8, 2, 3, 1, 5, 5, 8, 8, 5, 0, 9, 9, 2, 5, 7, 7, 2, 6, 1, 5,\n",
            "        6, 5, 6, 3, 7, 8, 1, 0, 1, 2, 1, 6, 8, 4, 4, 2, 0, 1, 3, 5, 1, 8, 3, 7,\n",
            "        9, 8, 2, 5, 4, 0, 4, 5, 0, 7, 2, 5, 3, 6, 4, 0]) 64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically we take one (usually the first) data point from a `dataloader`.\n",
        "\n",
        "This is used when:\n",
        "1. We need to do some EDA; or\n",
        "2. We are tesing the model on one data point."
      ],
      "metadata": {
        "id": "I7I6E4HKfppS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ],
      "metadata": {
        "id": "9Cb_G3l3fD17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "94ba4157-1e2a-47cc-ee72-73c4ed345558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer the following questions:\n",
        "\n",
        "1. Why `train_features[0]`?\n",
        "2. Why do we need `squeeze`? What does it do?"
      ],
      "metadata": {
        "id": "YdvLtgBXgHBe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:\n",
        "1. we just want the first image\n",
        "2. We want to remove the first dimension"
      ],
      "metadata": {
        "id": "fE99DsrGpp79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__NOTE__: once we load data in as tensors, we can use abovementioned tensor operations of transform it."
      ],
      "metadata": {
        "id": "ZO5Caoajgmqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "iYlpXjLFg5ZC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Network with `torch`\n",
        "\n",
        "Unlike `tensorflow`, NNs in `torch` are instances of subclass `nn.Module`. You can think of classes/objects as super variables with its own __functions__ and __methods__.\n",
        "\n",
        "In a `torch` NN, the two important function are:\n",
        "1. `__init__`: which initializes the architecture of the NN; and\n",
        "2. `forward`: which carrys forward propagation (move data through the layers in NN)."
      ],
      "metadata": {
        "id": "xuVdzFQDg_mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class linearNN(nn.Module): ##Parent or Super class\n",
        "    ## model architecture\n",
        "    def __init__(self): ## init creates the class/object\n",
        "        super().__init__() ## super refers to the parent/super class in line 5\n",
        "        self.flatten = nn.Flatten() ## first flatten layer, makes multi dimensional data one dimensional\n",
        "        ## we have two linear layers here\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512), ## part of 1st layer\n",
        "            nn.ReLU(), ## part of 1st layer\n",
        "            nn.Linear(512, 512), ## 2nd layer\n",
        "            nn.ReLU(), ## 2nd layer\n",
        "            nn.Linear(512, 10), ## 10 output due to 10 classes\n",
        "        )\n",
        "    ## forward prop\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        ## pred = nn.Softmax(dim=1)(logits).argmax(1)\n",
        "        return logits ## to check if something is wrong\n",
        "        ## return pred #### predicted class"
      ],
      "metadata": {
        "id": "79S3KqkNgCsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to use above NN, you need to assign it to a variable.\n",
        "\n",
        "__NOTE__: you can also use the `.to()` method to move it to the GPU (`device`)."
      ],
      "metadata": {
        "id": "69pUhrl8ie1w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = linearNN().to(device)\n",
        "print(model) ## this prints the model architecture"
      ],
      "metadata": {
        "id": "swEQc-HNiaiq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b5667d5-4242-4b93-d866-4b8df563e176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linearNN(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer the questions\n",
        "1. How many layers?\n",
        "2. Does each layer have an activation function, if so, what are they?"
      ],
      "metadata": {
        "id": "MhaHYyUgi2wp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 3 layers\n",
        "2. ReLU"
      ],
      "metadata": {
        "id": "eK6ytExXutvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the model, we pass it the input data. This executes the model’s forward, along with some [background operations](https://github.com/pytorch/pytorch/blob/270111b7b611d174967ed204776985cefca9c144/torch/nn/modules/module.py#L866). Do not call `model.forward()` directly!\n",
        "\n",
        "Calling the model on the input returns a 2-dimensional tensor with `dim=0` corresponding to each output of 10 raw predicted values for each class, and `dim=1` corresponding to the individual values of each output. We get the prediction probabilities by passing it through an instance of the `nn.Softmax` module."
      ],
      "metadata": {
        "id": "juW1ytrkjEq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device) ## random data\n",
        "logits = model(X)\n",
        "logits"
      ],
      "metadata": {
        "id": "PM0cyKULiyLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73da23ae-97dd-4a5b-a97c-80d6e4ef5f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0475, -0.1213, -0.1402,  0.0498,  0.0773,  0.1418, -0.0136,  0.0036,\n",
              "         -0.0031,  0.0947]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Answer the questions\n",
        "1. Can you explain the shape of the input data?\n",
        "2. Based on the `logits`, can you tell me which class is predicted?"
      ],
      "metadata": {
        "id": "L6dt10r3jgiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(-1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "id": "bqelQx8wjZ0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6cc2ce-eb3c-466a-e591-218475be58fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([5], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_probab.detach().cpu().numpy().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1zILYSSv0lp",
        "outputId": "e46e39a0-ad1c-4b88-f42b-12c14000d9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also look at the model paraemters - keep in mind we never trained `model` so the parameters are random!"
      ],
      "metadata": {
        "id": "pCDTDa2Kke-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ],
      "metadata": {
        "id": "mzNXBiTHjqpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e68f7cb7-ae06-41e8-967e-8ea9ea660af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: linearNN(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0060, -0.0164,  0.0101,  ...,  0.0032, -0.0275,  0.0123],\n",
            "        [-0.0084,  0.0151, -0.0283,  ...,  0.0050,  0.0133, -0.0019]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0317, 0.0019], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0097, -0.0021,  0.0418,  ...,  0.0282,  0.0228, -0.0385],\n",
            "        [-0.0402,  0.0216,  0.0189,  ..., -0.0191, -0.0387,  0.0152]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([0.0011, 0.0353], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0115,  0.0190,  0.0213,  ..., -0.0314, -0.0192,  0.0268],\n",
            "        [-0.0076,  0.0078,  0.0253,  ...,  0.0124,  0.0243,  0.0235]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0151, -0.0243], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training, Eval, and Optimization\n",
        "\n",
        "We know we need to train the NN so it can be more useful. Similar to `keras` we train model on __epochs__.\n",
        "\n",
        "In order to do that, we need to define a few more __hyperparameters__:"
      ],
      "metadata": {
        "id": "uAqMQtgMlmKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 1e-1 ## learning rate, 0.0001\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "_iAhYxHXkmLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you need a refresher:\n",
        "- __Number of Epochs__: the number times to iterate over the dataset\n",
        "\n",
        "- __Batch Size__: the number of data samples propagated through the network before the parameters are updated, in this case `64`\n",
        "\n",
        "- __Learning Rate__: how much to update models parameters at each batch/epoch. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training.\n",
        "\n"
      ],
      "metadata": {
        "id": "4psTMesAmYRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimization Loop\n",
        "Once we set our hyperparameters, we can then train and optimize our model with an optimization loop. Each iteration of the optimization loop is called an epoch.\n",
        "\n",
        "Each epoch consists of two main parts:\n",
        "- The Train Loop - iterate over the training dataset and try to converge to optimal parameters.\n",
        "\n",
        "- The Validation Loop - iterate over the validation dataset to check if model performance is improving. In this case let's just use the test set for demo purposes.\n",
        "\n",
        "In order to facilitate backpropagation, we need to define a loss function -- keep in mind the training purpose is to __minimize__ loss."
      ],
      "metadata": {
        "id": "Ig6Xr_z-mvNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loss Function\n",
        "When presented with some training data, our untrained network is likely not to give the correct answer. Loss function measures the degree of dissimilarity of obtained result to the target value, and it is the loss function that we want to minimize during training. To calculate the loss we make a prediction using the inputs of our given data sample and compare it against the true data label value.\n",
        "\n",
        "Common loss functions include [`nn.MSELoss`](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss) (Mean Square Error) for regression tasks, and [`nn.NLLLoss`](https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html#torch.nn.NLLLoss) (Negative Log Likelihood) for classification. [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) combines `nn.LogSoftmax` and `nn.NLLLoss`.\n",
        "\n",
        "We pass our model’s output logits to `nn.CrossEntropyLoss`, which will normalize the logits and compute the prediction error.\n",
        "\n"
      ],
      "metadata": {
        "id": "7YVSYDKCnJNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "9zn5XUYlmQzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Optimizer\n",
        "Optimization is the process of adjusting model parameters to reduce model error in each training step. Optimization algorithms define how this process is performed (in this example we use __Stochastic Gradient Descent__). All optimization logic is encapsulated in the `optimizer` object. Here, we use the SGD optimizer; additionally, there are [many different optimizers](https://pytorch.org/docs/stable/optim.html) available in PyTorch such as ADAM and RMSProp, that work better for different kinds of models and data.\n",
        "\n",
        "We initialize the optimizer by registering the model’s parameters that need to be trained, and passing in the learning rate hyperparameter."
      ],
      "metadata": {
        "id": "6GyesP0CnkpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR) ### parameters is the weights to optimize based on the loss and etc."
      ],
      "metadata": {
        "id": "uEZuJelinbzo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inside the training loop, optimization happens in three steps:\n",
        "1. Call `optimizer.zero_grad()` to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
        "\n",
        "2. Backpropagate the prediction loss with a call to `loss.backward()`. PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
        "\n",
        "3. Once we have our gradients, we call `optimizer.step()` to adjust the parameters by the gradients collected in the backward pass.\n",
        "\n",
        "Using the above logic, we define `train_loop` that loops over our optimization code, and `test_loop` that evaluates the model’s performance against our test data."
      ],
      "metadata": {
        "id": "Ds5GfhL1n-B8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        #### PREPROCESSING NEEDED HERE\n",
        "        X /= 255\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad(): ### Disable gradients; weights are frozen; No training\n",
        "        for X, y in dataloader: #### Prevent Leakage; Calculate Loss only\n",
        "            pred = model(X) #### pred is a tensor of float of gradient from GPU\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "0wsJqAIcn8ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize the loss function and optimizer, and pass it to `train_loop` and `test_loop`. Feel free to increase the number of epochs to track the model’s improving performance."
      ],
      "metadata": {
        "id": "Puz7ED_pobzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = linearNN()\n",
        "for t in range(EPOCHS):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "id": "FuAXDIfboZX7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "98303808-85aa-4cf4-ef76-b72cf7dfc450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.302428  [   64/60000]\n",
            "loss: 2.302148  [ 6464/60000]\n",
            "loss: 2.299504  [12864/60000]\n",
            "loss: 2.303064  [19264/60000]\n",
            "loss: 2.305381  [25664/60000]\n",
            "loss: 2.302389  [32064/60000]\n",
            "loss: 2.302205  [38464/60000]\n",
            "loss: 2.304200  [44864/60000]\n",
            "loss: 2.305101  [51264/60000]\n",
            "loss: 2.303958  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 8.7%, Avg loss: 2.302441 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.302015  [   64/60000]\n",
            "loss: 2.303619  [ 6464/60000]\n",
            "loss: 2.300392  [12864/60000]\n",
            "loss: 2.301260  [19264/60000]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-706d83ad700e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t+1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-104-ddef76c8f8e0>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NOTES:\n",
        "1. Sometimes datasets is something need to pay attention\n",
        "2. Bad dataset wont improve the performance of the model\n"
      ],
      "metadata": {
        "id": "py511rOM92JD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save & load model\n",
        "\n",
        "Please refer to [this tutorial](https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/11f1adacb7d237f2041ce267ac38abb6/saveloadrun_tutorial.ipynb)."
      ],
      "metadata": {
        "id": "j36ZkI0QpX9c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DO IT YOURSELF\n",
        "\n",
        "The `model` did not improve in the training process. Can you figure out why and try to make it perform better?"
      ],
      "metadata": {
        "id": "Ue1RdqnZqFHk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JwdyALIGol_s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}