{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnpj0UyEXnQS"
      },
      "source": [
        "# Deep Learning & Artificial Intelligence\n",
        "## Recurrent Neural Networks and Natrural Language Processing\n",
        "### Dr. Jie Tao, Fairfield University"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTGrpGOdDf3x"
      },
      "source": [
        "## NLP Basics\n",
        "\n",
        "- Text is one of the most widespread forms of **sequence** data.\n",
        "  - It can be sequence of _characters_ or _words_\n",
        "- The analysis of text data in general is called **Natural Language Processing** (NLP)\n",
        "  - With potential applications such as text classification, sentiment analysis, question answering\n",
        "- Deep Learning based NLP models recognize __patterns__ from words, sentences, or other linguistic units\n",
        "  - Same as how we use CNN to recognize patterns from pixels in images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGkZ9XekFPag"
      },
      "source": [
        "### How to Process Text\n",
        "\n",
        "- Like all other NN models, raw text (e.g., in natural English) cannot be processed\n",
        "  - We need to convert the words and sentencens into __real-valued tensors__\n",
        "- There are multiple ways to do this:\n",
        "  - Segment text to __words__, then tranform each word into a __vector__\n",
        "  - Segment text to __characters__, then tranform each character into a __vector__\n",
        "  - Extract $N$ consecutive words or characters together, and transform them into vectors. These $N$ consecutive words or characters are called __N-grams__, aka. bag-of-words.\n",
        "\n",
        "- Generally, the different units into which you can break down text (e.g., words, characters, or n-grams) are called **tokens**\n",
        "  - Specifically, __tokens__ refer to words or multi-word phrases only\n",
        "  - This segmentation process is called __tokenization__\n",
        "- Then we just need to associate rea;-valued vectors with the tokens - which is called **vectorization**. There are two ways of doing so:\n",
        "  - Our old friend One-hot Encoding, or\n",
        "  - Word Embedding\n",
        "\n",
        "- That's how we transform text in natural language into tensors (e.g., `NumPy` arrays) so `keras` can take them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggPa6FDRHCRt"
      },
      "source": [
        "### Tokenization & Vectorization\n",
        "\n",
        "![tokenization](https://drek4537l1klr.cloudfront.net/chollet/Figures/06fig01.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a95gbTLVHXjK"
      },
      "source": [
        "#### One-hot Encoding of Text\n",
        "\n",
        "- OHE is the most basic and common way of vectorization\n",
        "  - You can refer to L3, the IMDB data was OHE'ed\n",
        "  - Every word has a unique index `i` in the vocabulary (contains all possible words in the text)\n",
        "  - Each word is then converted into a binary vector\n",
        "    - the vector has a size of $N$ - the size of the vocabulary\n",
        "    - the vector has a value of `1` at the `i-th` position, rest are `0`s\n",
        "- We can perform OHE on __words__ and __characters__\n",
        "  - See example below for a word-level OHE\n",
        "  - Refer to Listing 6.2 for a character-level OHE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ_5vyNKFKRs",
        "outputId": "eaf70ce2-e777-4b68-df96-106ac8d54605"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "def ohe(samples, max_len = 10):\n",
        "  '''\n",
        "  INPUT:\n",
        "  ---\n",
        "  - samples (text): sequence of words/characters to be vectorized\n",
        "  ---\n",
        "  OUTPUT:\n",
        "  ---\n",
        "  - results (NumPy array): binary array, the appearing word is 1 rest are 0\n",
        "  '''\n",
        "  #### construct the vocabulary by adding all unique words to it\n",
        "  #### each word is assigned with an ID: {word : ID}\n",
        "  token_index = {}\n",
        "  for sample in samples:\n",
        "      for word in sample.split():\n",
        "          if word not in token_index:\n",
        "              #### the first word has an ID of 1, then 2, ...\n",
        "              token_index[word] = len(token_index) + 1\n",
        "  #### It's always a good practice to set a max_length\n",
        "  #### since rare words are usually less important\n",
        "  max_length = max_len\n",
        "  #### creating holders for the results, which is a 3D tensor\n",
        "  #### first dimension corresponds to how many samples are processed\n",
        "  #### second dimension corresponds to the length of sample (<= max_length)\n",
        "  #### third dimension correponds to the size of the vocabulary + 1\n",
        "  #### TRICK: the reason we need to have `+1` is we need to\n",
        "  #### capture words that are not in the vocabulary\n",
        "  results = np.zeros(shape=(len(samples),\n",
        "                            max_length,\n",
        "                            max(token_index.values()) + 1))\n",
        "  for i, sample in enumerate(samples):\n",
        "      #### if words appear and within `max_length`\n",
        "      for j, word in list(enumerate(sample.split()))[:max_length]:\n",
        "          index = token_index.get(word)\n",
        "          #### set it to 1\n",
        "          results[i, j, index] = 1.\n",
        "  return results\n",
        "\n",
        "ohe(samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "       [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP7tE6j9MCnL"
      },
      "source": [
        "Looks like a complex function, right? Luckily `keras` provides a utility function for us. Refer to the official docs [here](https://keras.io/api/preprocessing/text/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BCMkMbjLGGI",
        "outputId": "29c43da2-4b3e-494b-993d-fd5e24f3c30a"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# samples = ['The cat sat on the mat.', 'The dog ate my homework.']\n",
        "\n",
        "#### tokenizer automatically filter out punctuations, and convert text to lower case\n",
        "#### by default it splits text at word-level (on ' ')\n",
        "#### you can specify `char_level=True` to make it work at char-level\n",
        "#### you can also specify how you want to deal with out-of-vocabulary words\n",
        "#### with `oov_token=`, e.g., `UNK` (means unknown)\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "#### then you need to fit the tokenizer on the text\n",
        "tokenizer.fit_on_texts(samples)\n",
        "#### holding the word IDs\n",
        "sequences = tokenizer.texts_to_sequences(samples)\n",
        "#### start OHE\n",
        "one_hot_results = tokenizer.texts_to_matrix(samples, mode='binary')\n",
        "#### we can retrieve word indexes like below\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 9 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bwKuwMsBMTrz",
        "outputId": "8911186a-c954-40f2-961f-290a2a482b83"
      },
      "source": [
        "#### We can check the OHE results\n",
        "#### it is similar compared to our own `ohe` function\n",
        "one_hot_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr4jgC-dOkvH"
      },
      "source": [
        "__PRO TIP:__ If your vocabulary is too big, you can consider the __hashing trick__. Refer to Listing 6.4 on the textbook for help. Because of recent processing power, we are less concerned about the vocabulary size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ua3XniKO59a"
      },
      "source": [
        "#### Word Embeddings\n",
        "\n",
        "- Another __more powerful__ way for vectorization is called __word embedding__, where words are represented using _dense_ real-valued vectors, rather than _binary_ vectors with OHE\n",
        "\n",
        "| | OHE | Word Embedding |\n",
        "| --- | --- | --- |\n",
        "| values | binary | real-value (floats) |\n",
        "| sparcity | sparse (mostly `0`s) | dense (much less `0`s) |\n",
        "| dimensions | high | low |\n",
        "\n",
        "- With OHE vectors are usually tens of thousands in dimension, we can specify the dimensionality of our word embedding vectors\n",
        "  - although arbitrarily the magic number is `300`\n",
        "\n",
        "![OHE vs. WE](https://drek4537l1klr.cloudfront.net/chollet/Figures/06fig02.jpg)\n",
        "\n",
        "__PRO TIP__: Word Embeddings is the __preferred__ method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuZNtxApSy81"
      },
      "source": [
        "#### How to Learn Word Embeddings\n",
        "\n",
        "- The method is called __word2vec__, refer to [this post](http://jalammar.github.io/illustrated-word2vec/) for more information\n",
        "- You can learn your word embeddings in one of the two following ways:\n",
        "  - Learn word embeddings with your main NLP task (e.g., text classification, sentiment analysis)\n",
        "    - Set up random values in word vectors, then learn these values as your learn the wrights in the NN\n",
        "  - Load __pre-trained__ word embeddings and use them in your NLP task\n",
        "    - it's simiar to using pre-trained models in the CV tasks\n",
        "    - But in this case we are not using models but representations of the data (text)\n",
        "- Let's talk about the two methods one-by-one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8d4bBINVG4b"
      },
      "source": [
        "#### Learning Word Embedding\n",
        "\n",
        "- There is a specific Python package for word2vec called `gensim`\n",
        "  - [here](https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial) is a good tutorial for word2vec\n",
        "- Alternatively, we can use the `keras` `Embedding` layer for that\n",
        "  - It is an easier way, but it is not as specialized for word2vec\n",
        "  - In the `Embedding` layer, the word vectors are initialized with __random__ values\n",
        "    - These random vectors are not meaningful since two interchangeable words may end up in totally different vectors\n",
        "  - Thus, we need to __train__ these vectors, meaning learn the _actual, meaningful_ values in them\n",
        "- In other words, vectors have geometric relationships (e.g., parallel, intersect)\n",
        "  - So word vectors map human languages into a geometric space called __language space__\n",
        "  - In a valid language space, synonyms should be embedded in similar vectors\n",
        "  - And the words with different meanings should be more distance that words with similar meanings\n",
        "- See example below (pet --> wild animal):\n",
        "\n",
        "![word2vec ex](https://drek4537l1klr.cloudfront.net/chollet/Figures/06fig03.jpg)\n",
        "\n",
        "- Note that all word embeddings are language specific, English word embeddings, Chinese word embeddings, ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm75JDnJYw9J"
      },
      "source": [
        "#### `keras` `Embedding` Layer\n",
        "\n",
        "- The word embedding are not only language specific, but also task specific\n",
        "  - since the same word may mean different things in different context\n",
        "- Thus it is reasonable to train _different_ word embeddings for different tasks\n",
        "  - so we use the `keras` `Embedding` Layer as follows:\n",
        "```python\n",
        "from keras.layers import Embedding\n",
        "#### this layer let us to capture 1000 words in the vocabulary\n",
        "#### and embed them in 64-length vectors\n",
        "embedding_layer = Embedding(1000, 64)\n",
        "```\n",
        "- the `Embedding` layer maps word index (representing unique words) to real-valued vectors\n",
        "  - so the word index are integers, and are 2D tensors (vocab_size, vector_size)\n",
        "![emb_layer](https://drek4537l1klr.cloudfront.net/chollet/Figures/06fig04.jpg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAXjk7jvagOp"
      },
      "source": [
        "#### `keras` `Embedding` Layer\n",
        "\n",
        "- The `keras` `Embedding` Layer takes 2D tensors of integers as input\n",
        "  - with shape `(samples, sequence_length)`: `samples` are the number of text (e.g., sentences/paragraphs) in the collection (aka. corpus), and `sequence_length` is number of tokens in each sample.\n",
        "  - In practice, each token is represented in word index (integers)\n",
        "  - Theoretically, the `Embedding` Layer can take sequences of variant lengths\n",
        "    - but all sequences in the __same batch__ needs to be of the same lenght\n",
        "    - so in practice we usually set all sequences to be the same length\n",
        "    - we use the utility function `pad_sequence` to pad shorter sequences and truncate longer ones (see [doc](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) for help)\n",
        "\n",
        "- The `keras` `Embedding` Layer returns 3D floating-point tensor of shape `(samples, sequence_length, embedding_dimensionality)`\n",
        "  - Such a 3D tensor can then be processed by an **RNN** layer or a **1D convolution** layer\n",
        "- When train the NN, the weights in the `Embedding` Layer are also trained via __backpropagation__\n",
        "- After training, the embedding space will show a lot of structure—a kind of structure specialized for the specific problem for which you’re training your model.\n",
        "\n",
        "- See below for an example with the IMDB data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSaAAbsYOQ7q",
        "outputId": "becc0127-a2ba-47e0-8b57-17447859c691"
      },
      "source": [
        "#### import utilities\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "#### we take the most popular 10,000 words, and set length of each review at 20 words\n",
        "max_features = 10000\n",
        "maxlen = 20\n",
        "#### load data\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(\n",
        "    num_words=max_features)\n",
        "#### pad/truncate reviews\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bS7AD7n5lUaH",
        "outputId": "d7d35ff5-c29e-4697-fa9f-7dc4e15bf8e3"
      },
      "source": [
        "#### Build the model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, Embedding\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, 50, input_length=maxlen))\n",
        "#### no hidden layer\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "#### compile the model\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 50)            500000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 1001      \n",
            "=================================================================\n",
            "Total params: 501,001\n",
            "Trainable params: 501,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l28n2OnBmWKe",
        "outputId": "a4e03229-016a-425f-88fe-b6656d1c5cdf"
      },
      "source": [
        "#### Train the model\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 6s 5ms/step - loss: 0.6136 - acc: 0.6734 - val_loss: 0.5295 - val_acc: 0.7274\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.4495 - acc: 0.7922 - val_loss: 0.4937 - val_acc: 0.7564\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3815 - acc: 0.8303 - val_loss: 0.4965 - val_acc: 0.7560\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.3256 - acc: 0.8641 - val_loss: 0.5090 - val_acc: 0.7490\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2696 - acc: 0.8971 - val_loss: 0.5251 - val_acc: 0.7418\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.2180 - acc: 0.9234 - val_loss: 0.5511 - val_acc: 0.7408\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1726 - acc: 0.9433 - val_loss: 0.5814 - val_acc: 0.7368\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1349 - acc: 0.9589 - val_loss: 0.6161 - val_acc: 0.7280\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.1048 - acc: 0.9700 - val_loss: 0.6545 - val_acc: 0.7224\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 3s 4ms/step - loss: 0.0807 - acc: 0.9794 - val_loss: 0.6998 - val_acc: 0.7132\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ycYzMBvmfin"
      },
      "source": [
        "Considering we have basically no hidden layer in the model, and only look at the first 20 words in the reviews, the ~75% validation accuracy is not that bad.\n",
        "\n",
        "To improve the results, we can of course use RNN layers or 1D Conv layers into the model, or we can use __pre-trained__ embeddings, which will be discussed next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq1QVmzFm6jo"
      },
      "source": [
        "### Using pretrained word embeddings\n",
        "\n",
        "- Similar to using pre-trained models (e.g., `VGG16`) for CV tasks, a lot of cases you have little training data, you might not be able to learn the task-specific embedding\n",
        "- So we can load a __pre-trained__ word embedding, so that you can save your limited training data for train the models only\n",
        "- These pre-trained embeddings are built on word __coocurrence__, meaning what words appear in the same sentences or documents, in an _unsupervised_ way\n",
        "  - Which is also based on the [word2vec algorithm](https://code.google.com/archive/p/word2vec)\n",
        "  - The idea is that you do not have to let your `Embedding` layer initiates on __random__ weights, but the weights from a __pre-trained__ embedding\n",
        "- One of hte most popular pre-trained embedding is called **Global Vectors for Word Representation** ([GloVe](https://nlp.stanford.edu/projects/glove))\n",
        "  - which contains embeddings for millions of English words trained on millions of Wikipedia data and data Crawled from Google News\n",
        "- See below for an example using GloVe embedding in a network with a similar architecture comapred to the one above\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "cEhRsM7WmZ_e",
        "outputId": "fa4aa67a-a5ab-4311-e4ef-a7867a41b024"
      },
      "source": [
        "#### We need the raw text, not the one `keras` provided (word indexes)\n",
        "#### so we use `pandas` to read the data from GitHub\n",
        "import pandas as pd\n",
        "#### load review data\n",
        "review_url = 'https://raw.githubusercontent.com/DrJieTao/IMDB-Movie-Reviews/master/reviews.txt'\n",
        "review_df = pd.read_csv(review_url, header=None, names = ['text'])\n",
        "review_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bromwell high is a cartoon comedy . it ran at ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>story of a man who has unnatural feelings for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>homelessness  or houselessness as george carli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>airport    starts as a brand new luxury    pla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>brilliant over  acting by lesley ann warren . ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  bromwell high is a cartoon comedy . it ran at ...\n",
              "1  story of a man who has unnatural feelings for ...\n",
              "2  homelessness  or houselessness as george carli...\n",
              "3  airport    starts as a brand new luxury    pla...\n",
              "4  brilliant over  acting by lesley ann warren . ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "88ypMo3XuRZf",
        "outputId": "29dbda87-6040-4b74-cf4c-bc324c06d35f"
      },
      "source": [
        "#### since the labels are stored separately, we need to load the labels and concat them\n",
        "label_url = 'https://raw.githubusercontent.com/DrJieTao/IMDB-Movie-Reviews/master/labels.txt'\n",
        "label_df = pd.read_csv(label_url, header=None, names = ['labels'])\n",
        "label_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     labels\n",
              "0  positive\n",
              "1  negative\n",
              "2  positive\n",
              "3  negative\n",
              "4  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_un5JQMxu9yr",
        "outputId": "88888643-87bf-4988-9f00-43223edb36cf"
      },
      "source": [
        "#### let's encode the labels `positive = 1, negative = 0`\n",
        "label_df['labels_true'] = label_df['labels'].apply(lambda x: 1 if x == 'positive' else 0)\n",
        "label_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>labels_true</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>positive</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     labels  labels_true\n",
              "0  positive            1\n",
              "1  negative            0\n",
              "2  positive            1\n",
              "3  negative            0\n",
              "4  positive            1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpTKqC9SvcZf",
        "outputId": "d744472b-a2fd-4080-a93a-656cc92239e1"
      },
      "source": [
        "#### let's pre-process the data\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "#### also using the first 20 words\n",
        "maxlen = 20\n",
        "#### we purposely set a small training sample\n",
        "training_samples = 2000\n",
        "validation_samples = 10000\n",
        "#### also most popular 10000 words\n",
        "max_words = 10000\n",
        "\n",
        "texts = review_df.text.values ## NumPy array\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=maxlen)\n",
        "\n",
        "labels = label_df.labels_true.values\n",
        "print('Shape of data tensor:', data.shape)\n",
        "print('Shape of label tensor:', labels.shape)\n",
        "\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "\n",
        "x_train = data[:training_samples]\n",
        "y_train = labels[:training_samples]\n",
        "x_val = data[training_samples: training_samples + validation_samples]\n",
        "y_val = labels[training_samples: training_samples + validation_samples]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 74072 unique tokens.\n",
            "Shape of data tensor: (25000, 20)\n",
            "Shape of label tensor: (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nhKGx01w2Ah"
      },
      "source": [
        "We need to download the GloVe embeddings, we can use shell commands below for that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-cnAjQ-wlzY",
        "outputId": "1a9a1010-3b38-4470-c413-2b4a142a5d2f"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-20 19:33:40--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-06-20 19:33:40--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-06-20 19:33:41--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.07MB/s    in 2m 41s  \n",
            "\n",
            "2021-06-20 19:36:21 (5.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7TyLfRNzFQc"
      },
      "source": [
        "Since it is a zipped file, we need to unzip it so that we can use it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_WKNZOS3yPM9",
        "outputId": "94184d8d-7760-4521-b967-27aa0b004ea8"
      },
      "source": [
        "!unzip glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chTVLjTs0Wg9"
      },
      "source": [
        "We downloaded four files, which are pre-trained embeddings of 50, 100, 200 and 300 dimensions, respectively. For simplication we are going to use the 100d file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xPBiKas0Kuc",
        "outputId": "a30362bb-4070-40d4-a14f-8d7295e2333c"
      },
      "source": [
        "#### empty dict to hold embeddings\n",
        "embeddings_index = {}\n",
        "\n",
        "with open('/content/glove.6B.100d.txt') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7TRaWKh08Mv"
      },
      "source": [
        "Next, we need to get an `embedding_matrix` which we can then load into the `Embedding` layer as weights.\n",
        "\n",
        "The `embedding_matrix` needs to have a shape of `(max_words, embedding_dim)`. We defined `max_words` as 10,000 above, and we know we are using GloVe at 100 dimensions (`embedding_dim = 100`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXfzL5MX03iK"
      },
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_words:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RrhxIhz51f6_",
        "outputId": "01c00553-1eef-4337-f486-2a85e6e10f6b"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words,\n",
        "                    embedding_dim,\n",
        "                    weights=[embedding_matrix], # we use the pre-trained embedding here\n",
        "                    input_length=maxlen,\n",
        "                    trainable=False)) # we don't want the training to update the embedding values\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 20, 100)           1000000   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                64032     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,064,065\n",
            "Trainable params: 64,065\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba3Vmqja2bnD",
        "outputId": "6de3f385-23a4-475d-f1ee-061a776e9ac6"
      },
      "source": [
        "#### Complie and Train\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val))\n",
        "#### save the model\n",
        "\n",
        "model.save_weights('pre_trained_glove_model.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 14s 20ms/step - loss: 0.7490 - acc: 0.5099 - val_loss: 0.6817 - val_acc: 0.5605\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.6323 - acc: 0.6316 - val_loss: 0.6688 - val_acc: 0.5914\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.5484 - acc: 0.7423 - val_loss: 0.6742 - val_acc: 0.6004\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.4638 - acc: 0.7908 - val_loss: 0.6900 - val_acc: 0.6026\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.3949 - acc: 0.8283 - val_loss: 0.7533 - val_acc: 0.5918\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3215 - acc: 0.8842 - val_loss: 0.7452 - val_acc: 0.6055\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.2694 - acc: 0.9189 - val_loss: 0.7864 - val_acc: 0.6073\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.2168 - acc: 0.9395 - val_loss: 0.7970 - val_acc: 0.6092\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.1499 - acc: 0.9712 - val_loss: 0.9247 - val_acc: 0.5915\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.1165 - acc: 0.9791 - val_loss: 0.9315 - val_acc: 0.5957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkDPUaMI3IVO"
      },
      "source": [
        "We can train the model without the __pre-trained__ embedding for comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNTgpOuC2l31",
        "outputId": "d8b62331-d584-489c-cd8e-34a56840f3ba"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(max_words,\n",
        "                    embedding_dim,\n",
        "                    # weights=[embedding_matrix], # take out pre-trained embedding here\n",
        "                    input_length=maxlen,\n",
        "                    trainable=False))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 20, 100)           1000000   \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2000)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                64032     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,064,065\n",
            "Trainable params: 64,065\n",
            "Non-trainable params: 1,000,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UFzj_F63aF7",
        "outputId": "57dbdb60-921e-4491-8b64-14cc997d5c24"
      },
      "source": [
        "### Complie and Train\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 2s 17ms/step - loss: 0.6902 - acc: 0.5397 - val_loss: 0.6915 - val_acc: 0.5077\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.6607 - acc: 0.6513 - val_loss: 0.6889 - val_acc: 0.5339\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.6232 - acc: 0.7582 - val_loss: 0.6893 - val_acc: 0.5411\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5803 - acc: 0.7956 - val_loss: 0.6953 - val_acc: 0.5392\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5378 - acc: 0.8172 - val_loss: 0.6996 - val_acc: 0.5446\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.5005 - acc: 0.8282 - val_loss: 0.7101 - val_acc: 0.5460\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.4532 - acc: 0.8608 - val_loss: 0.7252 - val_acc: 0.5468\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.4135 - acc: 0.8729 - val_loss: 0.7426 - val_acc: 0.5471\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 1s 13ms/step - loss: 0.3744 - acc: 0.8953 - val_loss: 0.7636 - val_acc: 0.5471\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 1s 12ms/step - loss: 0.3449 - acc: 0.9087 - val_loss: 0.7868 - val_acc: 0.5468\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbE_qyPD3ez1"
      },
      "source": [
        "You can see the __pre-trained__ model actually helped."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJrwx56n3l4T"
      },
      "source": [
        "## Understanding RNN\n",
        "\n",
        "- Both MLP and CNN have __no memory__:\n",
        "  - meaning each input is processed independently, with no state kept between inputs\n",
        "  - for these networks to process sequence or temporal data, the entire sequence (e.g., the whole time series) need to the fed to the network at once\n",
        "  - hence the whole sequence is treated as a __single__ data point\n",
        "  - Take the IMDB movie review as an example\n",
        "    - The whole review is converted into one large tensor (with vectors of words) then processed in one go\n",
        "  - These are called __feedforward networks__\n",
        "- For us human, we read a sentence _word by word_\n",
        "  - we keep memories of the earlier parts of the sentence when reading the later parts\n",
        "  - The earlier parts of the sentence affect the meaning of the later part, and sometimes vice versa\n",
        "- From this idea, we present __Recurrent Neural Netowrk__ (RNN)\n",
        "\n",
        "![RNN1](https://miro.medium.com/max/1400/1*NKhwsOYNUT5xU7Pyf6Znhg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqCH2TdijlsP"
      },
      "source": [
        "### What is RNN?\n",
        "\n",
        "- RNN processes sequences by iterating through every element in the sequence\n",
        "- And keep a state containing the processed elements\n",
        "- Essentially, RNN contains a internal loop, see below:\n",
        "  - recurrent is a different way of saying loops\n",
        "\n",
        "![RNN](https://miro.medium.com/max/450/1*T_ECcHZWpjn0Ki4_4BEzow.gif)\n",
        "\n",
        "- The remembered state are reset between processing two different sequences\n",
        "  - e.g., two IMDB reviews\n",
        "  - Thus, one and only one input at a time\n",
        "  - But the network is trained in multiple steps - each step corresponds to one element in the sequence (e.g., words in a review)\n",
        "- You can refer to [this post](https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9) for more information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFzczA9Bk4jB"
      },
      "source": [
        "### How RNN works?\n",
        "\n",
        "- Let's use a simple example to illustrate how RNN works\n",
        "- This RNN takes a 2D tensor (shape `(timesteps, input_features)`) by looping through all timesteps $ t \\in T $\n",
        "  - at a specific timestep $t$, the input sequence $X_t$ (shape `(input_features,)`), and process an output of $y_t$\n",
        "  - Keep the hidden state $y_t$ as $h_{t+1}$\n",
        "  - There is no hidden state for the first step, so we can select a all-zero vector in the shape of `(input_features,)`\n",
        "- In essence, RNN is a loop that uses the output from the previous step\n",
        "  - RNN can be defined by the activation function, like the `tanh` in the example below\n",
        "- We can use this psuedo code to express this RNN (say we use a `Dense` layer in there):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b7-ZZ1W3c9s",
        "outputId": "b6581014-729d-46a0-eb23-7819ff2476c3"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "timesteps = 100\n",
        "input_features = 32\n",
        "output_features = 64\n",
        "\n",
        "inputs = np.random.random((timesteps, input_features))\n",
        "\n",
        "state_t = np.zeros((output_features,))\n",
        "\n",
        "W = np.random.random((output_features, input_features))\n",
        "U = np.random.random((output_features, output_features))\n",
        "b = np.random.random((output_features,))\n",
        "\n",
        "successive_outputs = []\n",
        "#### here is the recurrent part\n",
        "for input_t in inputs:\n",
        "    output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b)\n",
        "\n",
        "    successive_outputs.append(output_t)\n",
        "\n",
        "    state_t = output_t\n",
        "\n",
        "final_output_sequence = np.concatenate(successive_outputs, axis=0)\n",
        "final_output_sequence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.99999999, 0.99999888, 0.99999519, ..., 1.        , 1.        ,\n",
              "       1.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIC8uWSfoOB8"
      },
      "source": [
        "#### `keras` RNN Layers\n",
        "\n",
        "Refer to the example below using `SimpleRNN` layers on the IMDB data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgsCH-FjoNub",
        "outputId": "7b2d1aa9-4131-4703-cf32-b48c76e10b8c"
      },
      "source": [
        "#### load the data\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_features = 10000\n",
        "maxlen = 500\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(input_train, y_train), (input_test, y_test) = imdb.load_data(\n",
        "     num_words=max_features)\n",
        "print(len(input_train), 'train sequences')\n",
        "print(len(input_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "input_train = pad_sequences(input_train, maxlen=maxlen)\n",
        "input_test = pad_sequences(input_test, maxlen=maxlen)\n",
        "print('input_train shape:', input_train.shape)\n",
        "print('input_test shape:', input_test.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "input_train shape: (25000, 500)\n",
            "input_test shape: (25000, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsAoL086om7D"
      },
      "source": [
        "Let’s train a simple recurrent network using an `Embedding` layer and a `SimpleRNN` layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaZMGPSHng6g",
        "outputId": "c3ecaf46-4925-4e37-c30e-c7fb55fa1dc3"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n",
        "#### define model\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 32)          320000    \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 322,113\n",
            "Trainable params: 322,113\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbvcLOIposDQ",
        "outputId": "9d23bfd6-ebe2-461f-bd7c-cd2e96a4a968"
      },
      "source": [
        "#### compliing and train\n",
        "#### since we are going word by word, the training is much longer\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(input_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 213s 339ms/step - loss: 0.5817 - acc: 0.6707 - val_loss: 0.4166 - val_acc: 0.8152\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 211s 337ms/step - loss: 0.3546 - acc: 0.8544 - val_loss: 0.4070 - val_acc: 0.8440\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 210s 336ms/step - loss: 0.2742 - acc: 0.8917 - val_loss: 0.3924 - val_acc: 0.8228\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 210s 337ms/step - loss: 0.2332 - acc: 0.9103 - val_loss: 0.3246 - val_acc: 0.8674\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 209s 335ms/step - loss: 0.1946 - acc: 0.9266 - val_loss: 0.3429 - val_acc: 0.8740\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 208s 333ms/step - loss: 0.1849 - acc: 0.9291 - val_loss: 0.3733 - val_acc: 0.8634\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 209s 334ms/step - loss: 0.1403 - acc: 0.9499 - val_loss: 0.4264 - val_acc: 0.8442\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 209s 335ms/step - loss: 0.1069 - acc: 0.9625 - val_loss: 0.4417 - val_acc: 0.8502\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 208s 333ms/step - loss: 0.0927 - acc: 0.9689 - val_loss: 0.4908 - val_acc: 0.8342\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 207s 331ms/step - loss: 0.0724 - acc: 0.9754 - val_loss: 0.5792 - val_acc: 0.8494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owEDY-ptq0K_"
      },
      "source": [
        "### Problems with RNN\n",
        "\n",
        "- You can see the model overfitted soon - the best performance is 0.8816 of `val_acc` at epoch `5`. But one key problem is __vanishing gradients__.\n",
        "\n",
        "- Recall how backpropgation works?\n",
        "\n",
        "![bp](https://miro.medium.com/max/450/1*8eriEDJZisidMG_yyEDEAA.gif)\n",
        "\n",
        "- As the backpropgation goes to the earlier layers, the gradients decrease geometrically:\n",
        "\n",
        "![diminishing gradients](https://miro.medium.com/max/450/1*nGrmK1Ikx7ecZZyTdOCIuQ.gif)\n",
        "\n",
        "- Particularly for RNN, there is an additional layer with steps in the sequence:\n",
        "\n",
        "![RNN-DG](https://miro.medium.com/max/864/1*Ku54qmCryZVBaIc6g8rjGA.gif)\n",
        "\n",
        "- That is the reason we use less and less RNN layers, but more advanced recurrent layers, such as `LSTM` and `GRU` layers, which we are going to discuss below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPF7GlpfUM8D"
      },
      "source": [
        "### Understanding LSTM and GRU\n",
        "\n",
        "- Due to the vanishing gradient problem, we hardly use any pure RNN layers\n",
        "- Luckily, we have other two recurrent layers to use: `LSTM` and `GRU`\n",
        "  - Long Short-Term Memory (LSTM) algorithm is a variant of RNN\n",
        "  - While Gated Recurrent Unit (GRU) is another variant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzE3kVxaVPgd"
      },
      "source": [
        "### LSTM Explained\n",
        "\n",
        "- LSTM has a similar control flow as the regular RNN\n",
        "  - It processes sequence in steps, and propagates forward\n",
        "- The key difference is within the LSTM cells\n",
        "\n",
        "![LSTM-cell](https://miro.medium.com/max/576/1*0f8r3Vd-i4ueYND1CUrhMA.png)\n",
        "\n",
        "- The core concepts of LSTM include:\n",
        "  - The cell state: the cell state is similar to the RNN cell state, which remembers the state from the previous step - that is the __memory__ part\n",
        "  - In RNN, the __memory__ remembers all the information throughout the sequence\n",
        "  - However, in real life, the __short-term__ memory carries more importance\n",
        "    - Consider this example: \"I am Chinese so I speak _____. \"\n",
        "      - To predict the word in blank, the hints \"speak\" and \"Chinese\" are more important - they are short-term memory.\n",
        "  - Gates: Determines what information to be kept or forgotten\n",
        "    - Specifically, what information is __allowed__ at a certain cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4_lI2NVW9Rp"
      },
      "source": [
        "#### What is a Gate?\n",
        "\n",
        "- Simply speaking, a __gate__ is a `sigmoid` function:\n",
        "  - `sigmoid` has outputs between `0` and `1`, and we can use a threshold to control it to output only `0` and `1`\n",
        "  - In this context, `0` means to __forget__ since anything multiply by `0` is `0`\n",
        "  - And `1` means to __keep__ since anything multiply by `1` is itself\n",
        "- A LSTM cell contains three types of gates:\n",
        "  - Forget Gate: decides what is relevant to keep from **prior steps**\n",
        "  - Input Gate: what information is relevant to add from **the current step**\n",
        "  - Output Gate: determines what the next hidden state should be"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_bUyP_NYIVc"
      },
      "source": [
        "#### What is a Forget Gate?\n",
        "\n",
        "- Forget gates decide what information to __forget__ or __keep__\n",
        "  - Previous hidden state ($h_t$) and the current input ($X_{t+1}$) are fed into a `sigmoid` function\n",
        "  - If the information is \"far away\" -- meaning __long-term__ memory -- the hidden state is low, so it is more likely that the `sigmoid` function outputs a value closer to `0`; thus, these information are to be __forgotten__.\n",
        "\n",
        "![forget gate](https://miro.medium.com/max/576/1*GjehOa513_BgpDDP6Vkw2Q.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxF8FEdzZDF5"
      },
      "source": [
        "#### What is an Input Gate?\n",
        "\n",
        "- The input gate is used to update the __hidden/cell state__ of the current cell\n",
        "- The input gate contains a `sigmoid` and a `tanh` function\n",
        "  - This `sigmoid` function decides if the information is important\n",
        "    - You can consider the outputs ($sigmoid(h_{t-1}, X_t)$) as weights: `0`: non-important, `1`: important\n",
        "  - the output of the `tanh` function ($tanh(h_{t-1}, X_t)$) is between `-1` and `1`\n",
        "    - This helps regulate the network\n",
        "- You then multiply the outputs from the `sigmoid` and `tanh` function together\n",
        "  - This decides what information is important enough to keep\n",
        "  - Which is given by:\n",
        "\n",
        "$$ c_t = sigmoid(h_{t-1}, X_t) \\cdot tanh(h_{t-1}, X_t) $$\n",
        "\n",
        "![input gate](https://miro.medium.com/max/576/1*TTmYy7Sy8uUXxUXfzmoKbA.gif)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhHaRnZdaLvw"
      },
      "source": [
        "#### How to Update Cell State?\n",
        "\n",
        "- The cell state at timestep ($t$) is given by:\n",
        "\n",
        "$$ c_t = f_t \\cdot c_{t-1} + c_t$$, where $c_t$ is given above, and $c_{t-1}$ is the cell state from the previous step\n",
        "\n",
        "- In other words, the forget gate decides how much information from the previous step should be passed to the current step, and\n",
        "- the input gate decides how important is the current input\n",
        "\n",
        "![cell state](https://miro.medium.com/max/576/1*S0rXIeO_VoUVOyrYHckUWg.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZOgqyN-ctno"
      },
      "source": [
        "#### What is an Output Gate?\n",
        "\n",
        "- The output gate decides what the hidden state in the next step ($C_{t+1}$) would be\n",
        "  - Specifically, it determines what information should be passed to the next cell\n",
        "- The output gate also contains a `sigmoid` and a `tanh` function:\n",
        "  - We use the `sigmoid` to compute the importance of the current hidden state ($o_t = sigmoid(h_{t-1}, X_t)$)\n",
        "  - We use the `tanh` to compute the cell state to be passed to the next cell ($h_t$), given by:\n",
        "\n",
        "$$ h_t = sigmoid(h_{t-1}, X_t) \\cdot tanh(c_t) $$\n",
        "\n",
        "- Both $h_t$ and $c_t$ are passed into the next step ($ t+1 $).\n",
        "- Note we also use the hidden state for prediction\n",
        "\n",
        "![output gate](https://miro.medium.com/max/576/1*VOXRGhOShoWWks6ouoDN3Q.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwQ-roEdfd3a"
      },
      "source": [
        "#### Pseudo Code for LSTM\n",
        "\n",
        "- We can use following pseudo code to represent how a LSTM cell works\n",
        "```python\n",
        "def LSTMcell(prev_ct, prev_ht, Xt):\n",
        "  '''\n",
        "  INPUT:\n",
        "  ---\n",
        "  - prev_ct: cell state from previous step\n",
        "  - prev_ht: hidden state from previous step\n",
        "  OUTPUT:\n",
        "  ---\n",
        "  - ct: cell state of current step\n",
        "  - ht: hidden state of current step\n",
        "  '''\n",
        "  #### concatenate prew_ht and Xt\n",
        "  combined = prew_ht + Xt\n",
        "  #### calculate what to forget and what to keep\n",
        "  ft = sigmoid(combined)\n",
        "  #### calculate the candicate cell state ct\n",
        "  candidate = tanh(combined)\n",
        "  #### calculate the importance at the input gate\n",
        "  it = sigmoid(combined)\n",
        "  #### calculate current cell state\n",
        "  ct = prev_ct * ft + candidate * it\n",
        "  #### calculate the importance at the output gate\n",
        "  ot = sigmoid(combined) # same as it mostly\n",
        "  #### calculate hidden state\n",
        "  ht = ot * tanh(ct)\n",
        "  return ct, ht\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC-SVoGphlAF"
      },
      "source": [
        "### GRU Explained\n",
        "\n",
        "- With LSTM explained, GRU is fairly staightforward\n",
        "- GRU is a new generation of RNN, which is similar to LSTM\n",
        "- It contains only two gates:\n",
        "  - update gate: is similar to the combination of forget and input gates in LSTM\n",
        "    - decides what information to forget/keep\n",
        "  - reset gate: decides how much past information to forget\n",
        "- Theoretically since GRU has less gates (_tensor operations_) it is usually faster to train\n",
        "- But there is no guarantee which one gives the better performance\n",
        "\n",
        "__PRO TIP__: we usually build LSTM and GRU models together, and pick whichever gives us the better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB87LiRViqgO"
      },
      "source": [
        "### A Brief LSTM and GRU Example\n",
        "\n",
        "- Let's use the `LSTM` and `GRU` layers from `keras` on the IMDB data again here.\n",
        "  - This might be a good time you change your runtime type to use `GPU` as the hardware accelerator, since both models takes __longer__ to train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gun1pFB9pCIo",
        "outputId": "84ce1f45-0558-44d1-8cd7-38b6b6827fda"
      },
      "source": [
        "#### load the data\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_features = 10000\n",
        "maxlen = 500\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(input_train, y_train), (input_test, y_test) = imdb.load_data(\n",
        "     num_words=max_features)\n",
        "print(len(input_train), 'train sequences')\n",
        "print(len(input_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "input_train = pad_sequences(input_train, maxlen=maxlen)\n",
        "input_test = pad_sequences(input_test, maxlen=maxlen)\n",
        "print('input_train shape:', input_train.shape)\n",
        "print('input_test shape:', input_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "input_train shape: (25000, 500)\n",
            "input_test shape: (25000, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vpWa3kzi7Nq",
        "outputId": "849101f2-c462-4e57-dc81-9281da91cd27"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(input_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 10s 31ms/step - loss: 0.5028 - acc: 0.7634 - val_loss: 0.3637 - val_acc: 0.8594\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.2855 - acc: 0.8901 - val_loss: 0.3280 - val_acc: 0.8638\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.2330 - acc: 0.9124 - val_loss: 0.3101 - val_acc: 0.8708\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.2020 - acc: 0.9251 - val_loss: 0.4619 - val_acc: 0.8256\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.1739 - acc: 0.9354 - val_loss: 0.2983 - val_acc: 0.8802\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.1551 - acc: 0.9452 - val_loss: 0.3048 - val_acc: 0.8672\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.1420 - acc: 0.9493 - val_loss: 0.3135 - val_acc: 0.8838\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 0.1291 - acc: 0.9551 - val_loss: 0.3120 - val_acc: 0.8810\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.1190 - acc: 0.9585 - val_loss: 0.3689 - val_acc: 0.8832\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 0.1092 - acc: 0.9614 - val_loss: 0.3944 - val_acc: 0.8724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykly7gj5klyl"
      },
      "source": [
        "We can see our LSTM model get the best `val_acc` ~ 89% at epoch 9.\n",
        "\n",
        "Let's try a GRU model as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAWdG-imjJwL",
        "outputId": "b7a82de6-065e-4fa5-dfa5-4315c9099b31"
      },
      "source": [
        "from tensorflow.keras.layers import GRU\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 32))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(input_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 6s 30ms/step - loss: 0.5199 - acc: 0.7543 - val_loss: 0.3710 - val_acc: 0.8384\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.3002 - acc: 0.8808 - val_loss: 0.4140 - val_acc: 0.8504\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 0.2400 - acc: 0.9103 - val_loss: 0.3191 - val_acc: 0.8660\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 0.2039 - acc: 0.9252 - val_loss: 0.3087 - val_acc: 0.8868\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 4s 27ms/step - loss: 0.1803 - acc: 0.9338 - val_loss: 0.3191 - val_acc: 0.8662\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 0.1631 - acc: 0.9409 - val_loss: 0.4246 - val_acc: 0.8720\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 0.1469 - acc: 0.9484 - val_loss: 0.3644 - val_acc: 0.8742\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 0.1350 - acc: 0.9531 - val_loss: 0.3238 - val_acc: 0.8764\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 0.1229 - acc: 0.9578 - val_loss: 0.3340 - val_acc: 0.8780\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 4s 28ms/step - loss: 0.1179 - acc: 0.9578 - val_loss: 0.3634 - val_acc: 0.8736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4PUkvfUk-RA"
      },
      "source": [
        "We can see the results are almost identical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kaVDrEDlJXH"
      },
      "source": [
        "## Advanced Use of RNN Layers\n",
        "\n",
        "- From above results, we can observe a few things:\n",
        "  - Even though the `GRU` and the `LSTM` models are far more expensive, the performance improvements are not as impressive as expected\n",
        "  - Both the `GRU` and the `LSTM` models __overfit__ easily\n",
        "- In practice, we use following techniques to fight these issues:\n",
        "  - We **stack** `LSTM` or `GRU` layers up for better representation of the data\n",
        "  - We use **Bi-directional** `LSTM` or `GRU` layers since the dependency may be in both directions\n",
        "  - And we use `recurrent_dropout` to fight the overfitting problem\n",
        "- We discuss these techniques below, with a regression problem\n",
        "  - This is a weather forecasting problem\n",
        "  - Using features, such as  atmospheric pressure, humidity, wind direction to forecast air temperature in the next 24 hours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKiXy0ovkyNJ",
        "outputId": "444f0d5e-6ff5-4d26-8db0-cfe354234050"
      },
      "source": [
        "#### getting the data\n",
        "!wget https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
        "!unzip jena_climate_2009_2016.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-20 20:20:47--  https://s3.amazonaws.com/keras-datasets/jena_climate_2009_2016.csv.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.9.166\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.9.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13565642 (13M) [application/zip]\n",
            "Saving to: ‘jena_climate_2009_2016.csv.zip’\n",
            "\n",
            "jena_climate_2009_2 100%[===================>]  12.94M  84.9MB/s    in 0.2s    \n",
            "\n",
            "2021-06-20 20:20:47 (84.9 MB/s) - ‘jena_climate_2009_2016.csv.zip’ saved [13565642/13565642]\n",
            "\n",
            "Archive:  jena_climate_2009_2016.csv.zip\n",
            "  inflating: jena_climate_2009_2016.csv  \n",
            "  inflating: __MACOSX/._jena_climate_2009_2016.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "qK1fTxwinOGe",
        "outputId": "57f061a7-a846-4039-b8cd-89e9e910e84f"
      },
      "source": [
        "#### read in the data\n",
        "fname = 'jena_climate_2009_2016.csv'\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "weather_df = pd.read_csv(fname, index_col=0)\n",
        "weather_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p (mbar)</th>\n",
              "      <th>T (degC)</th>\n",
              "      <th>Tpot (K)</th>\n",
              "      <th>Tdew (degC)</th>\n",
              "      <th>rh (%)</th>\n",
              "      <th>VPmax (mbar)</th>\n",
              "      <th>VPact (mbar)</th>\n",
              "      <th>VPdef (mbar)</th>\n",
              "      <th>sh (g/kg)</th>\n",
              "      <th>H2OC (mmol/mol)</th>\n",
              "      <th>rho (g/m**3)</th>\n",
              "      <th>wv (m/s)</th>\n",
              "      <th>max. wv (m/s)</th>\n",
              "      <th>wd (deg)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>01.01.2009 00:10:00</th>\n",
              "      <td>996.52</td>\n",
              "      <td>-8.02</td>\n",
              "      <td>265.40</td>\n",
              "      <td>-8.90</td>\n",
              "      <td>93.3</td>\n",
              "      <td>3.33</td>\n",
              "      <td>3.11</td>\n",
              "      <td>0.22</td>\n",
              "      <td>1.94</td>\n",
              "      <td>3.12</td>\n",
              "      <td>1307.75</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.75</td>\n",
              "      <td>152.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>01.01.2009 00:20:00</th>\n",
              "      <td>996.57</td>\n",
              "      <td>-8.41</td>\n",
              "      <td>265.01</td>\n",
              "      <td>-9.28</td>\n",
              "      <td>93.4</td>\n",
              "      <td>3.23</td>\n",
              "      <td>3.02</td>\n",
              "      <td>0.21</td>\n",
              "      <td>1.89</td>\n",
              "      <td>3.03</td>\n",
              "      <td>1309.80</td>\n",
              "      <td>0.72</td>\n",
              "      <td>1.50</td>\n",
              "      <td>136.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>01.01.2009 00:30:00</th>\n",
              "      <td>996.53</td>\n",
              "      <td>-8.51</td>\n",
              "      <td>264.91</td>\n",
              "      <td>-9.31</td>\n",
              "      <td>93.9</td>\n",
              "      <td>3.21</td>\n",
              "      <td>3.01</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.88</td>\n",
              "      <td>3.02</td>\n",
              "      <td>1310.24</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.63</td>\n",
              "      <td>171.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>01.01.2009 00:40:00</th>\n",
              "      <td>996.51</td>\n",
              "      <td>-8.31</td>\n",
              "      <td>265.12</td>\n",
              "      <td>-9.07</td>\n",
              "      <td>94.2</td>\n",
              "      <td>3.26</td>\n",
              "      <td>3.07</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.92</td>\n",
              "      <td>3.08</td>\n",
              "      <td>1309.19</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.50</td>\n",
              "      <td>198.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>01.01.2009 00:50:00</th>\n",
              "      <td>996.51</td>\n",
              "      <td>-8.27</td>\n",
              "      <td>265.15</td>\n",
              "      <td>-9.04</td>\n",
              "      <td>94.1</td>\n",
              "      <td>3.27</td>\n",
              "      <td>3.08</td>\n",
              "      <td>0.19</td>\n",
              "      <td>1.92</td>\n",
              "      <td>3.09</td>\n",
              "      <td>1309.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.63</td>\n",
              "      <td>214.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     p (mbar)  T (degC)  ...  max. wv (m/s)  wd (deg)\n",
              "Date Time                                ...                         \n",
              "01.01.2009 00:10:00    996.52     -8.02  ...           1.75     152.3\n",
              "01.01.2009 00:20:00    996.57     -8.41  ...           1.50     136.1\n",
              "01.01.2009 00:30:00    996.53     -8.51  ...           0.63     171.6\n",
              "01.01.2009 00:40:00    996.51     -8.31  ...           0.50     198.0\n",
              "01.01.2009 00:50:00    996.51     -8.27  ...           0.63     214.3\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8jKqUeOnfx5",
        "outputId": "ec987686-11f7-4c98-ebe8-7d21343c33a0"
      },
      "source": [
        "#### look at the information of `weather_df`\n",
        "weather_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 420451 entries, 01.01.2009 00:10:00 to 01.01.2017 00:00:00\n",
            "Data columns (total 14 columns):\n",
            " #   Column           Non-Null Count   Dtype  \n",
            "---  ------           --------------   -----  \n",
            " 0   p (mbar)         420451 non-null  float64\n",
            " 1   T (degC)         420451 non-null  float64\n",
            " 2   Tpot (K)         420451 non-null  float64\n",
            " 3   Tdew (degC)      420451 non-null  float64\n",
            " 4   rh (%)           420451 non-null  float64\n",
            " 5   VPmax (mbar)     420451 non-null  float64\n",
            " 6   VPact (mbar)     420451 non-null  float64\n",
            " 7   VPdef (mbar)     420451 non-null  float64\n",
            " 8   sh (g/kg)        420451 non-null  float64\n",
            " 9   H2OC (mmol/mol)  420451 non-null  float64\n",
            " 10  rho (g/m**3)     420451 non-null  float64\n",
            " 11  wv (m/s)         420451 non-null  float64\n",
            " 12  max. wv (m/s)    420451 non-null  float64\n",
            " 13  wd (deg)         420451 non-null  float64\n",
            "dtypes: float64(14)\n",
            "memory usage: 48.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozS6ghPioHne",
        "outputId": "19ac1f1d-bdc2-45be-b492-39b6aa9d84d2"
      },
      "source": [
        "#### get the values from pandas into a NumPy array\n",
        "#### note taht we do not need the index\n",
        "data = weather_df.values\n",
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(420451, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaDe8WKbovHE"
      },
      "source": [
        "Of course for any forecasting problem we need to look at the general trends using visualizations. For instance the celsius temperature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "SaMd1L7wokt6",
        "outputId": "4f8dd3ed-2346-40b9-cf9c-5ed347ddbeb3"
      },
      "source": [
        "weather_df['T (degC)'].plot(figsize=(20,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f024d7d0890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x216 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fkhzVTPpdGU"
      },
      "source": [
        "Clearly we observe a seasonal trend.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIebDuZrvuUe"
      },
      "source": [
        "### The Analytical Problem\n",
        "\n",
        "The true analytical questions is:\n",
        "\n",
        "\n",
        "> Given the weathre data from the past $N$ timesteps (with each timestep as `10` minutes, as shown in the index of the DF), can you predict the temperature in the future $M$ timesteps?\n",
        "\n",
        "To Analyze this question, we need to define a few things:\n",
        "- $N$, aka. `lookback`, how many observations we would go back\n",
        "  - Let's say `10` days, which means `240` hours or `14400` minutes, so `lookback = 1440` (steps)\n",
        "- $M$, aka. `delay`, how many observations we need to predict forward\n",
        "  - We need to predict `24` hours or `1440` minutes, so `delay = 144`.\n",
        "- We also need to define the frequency of our sampling, aka. `steps`\n",
        "  - Let's say we sample the data hourly, or every `60` minutes, so `steps = 6`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ee2Us4mpIuO"
      },
      "source": [
        "lookback = 1440\n",
        "steps = 6\n",
        "delay = 144\n",
        "#### we can also define batch_size here\n",
        "batch_size = 128\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsfCX152v2z0"
      },
      "source": [
        "### Preprocessing the Data\n",
        "\n",
        "- Since the data is numerical, we do not need vectorization\n",
        "- But we do need to standardize our data, such as a `z-score` transformation:\n",
        "$$ z = \\frac{x-\\bar{x}}{\\mu}$$\n",
        "  - We should only use $\\bar{x}$ and $\\mu$ from the training data (say first `200000` observations)\n",
        "  - This step is very important because it avoids the __leak into the future__ problem\n",
        "- We also need to pass the data in a generator so that\n",
        "  - sample batches of data within the range determined by `lookback`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv0iQF0kv16u"
      },
      "source": [
        "#### z-score transformatin\n",
        "#### we can always use standardscaler from sklean\n",
        "#### but it is so simple we can do it in numpy\n",
        "mean = data[:200000].mean(axis=0)\n",
        "data -= mean\n",
        "std = data[:200000].std(axis=0)\n",
        "data /= std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC9gbSRExTA4"
      },
      "source": [
        "#### generator function\n",
        "import numpy as np\n",
        "\n",
        "def generator(data, lookback, delay, min_index, max_index,\n",
        "              shuffle=False, batch_size=128, step=6):\n",
        "    '''\n",
        "    Generates batches of data with defined sampling.\n",
        "    INPUT:\n",
        "    ---\n",
        "    - data (NumPy array): The original array of floating-point datanormalized.\n",
        "    - lookback (int): How many timesteps back the input data should go.\n",
        "    - delay (int): How many timesteps in the future the target should be.\n",
        "    - min_index and max_index (int): Segment data into train, validation and testing\n",
        "    - shuffle (bool): Whether to shuffle the samples or draw them in chronological order.\n",
        "    - batch_size (int): The number of samples per batch.\n",
        "    - step (int): The period, in timesteps, at which you sample data.\n",
        "    OUTPUT:\n",
        "    ---\n",
        "    samples (NumPy array): train, validation, test samples containing features\n",
        "    targets (NumPy array): train, validation, test targets.\n",
        "    '''\n",
        "    #### if we do not want to reserve data for validation\n",
        "    #### only use `delay` data for testing\n",
        "    if max_index is None:\n",
        "        max_index = len(data) - delay - 1\n",
        "    #### starting point: if `min_index` = 0 then we start at `lookback`\n",
        "    #### since we want to make sure the every sample, including the first one\n",
        "    #### contains `lookback` number of steps\n",
        "    i = min_index + lookback\n",
        "    while 1:\n",
        "        #### random sampling\n",
        "        if shuffle:\n",
        "            rows = np.random.randint(i, max_index, size=batch_size)\n",
        "        #### ordered sampleing\n",
        "        else:\n",
        "            if i + batch_size >= max_index:\n",
        "                i = min_index + lookback\n",
        "            rows = np.arange(i, min(i + batch_size, max_index))\n",
        "            i += len(rows)\n",
        "\n",
        "        samples = np.zeros((len(rows),\n",
        "                           lookback // step,\n",
        "                           data.shape[-1]))\n",
        "        targets = np.zeros((len(rows),))\n",
        "        for j, row in enumerate(rows):\n",
        "            indices = range(rows[j] - lookback, rows[j], step)\n",
        "            samples[j] = data[indices]\n",
        "            targets[j] = data[rows[j] + delay][1]\n",
        "        yield samples, targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxMeUW_vzuj9"
      },
      "source": [
        "#### geerating samples and targets\n",
        "train_gen = generator(data,\n",
        "                      lookback=lookback,\n",
        "                      delay=delay,\n",
        "                      min_index=0,\n",
        "                      max_index=200000,\n",
        "                      shuffle=True,\n",
        "                      step=steps,\n",
        "                      batch_size=batch_size)\n",
        "val_gen = generator(data,\n",
        "                    lookback=lookback,\n",
        "                    delay=delay,\n",
        "                    min_index=200001,\n",
        "                    max_index=220000,\n",
        "                    step=steps,\n",
        "                    batch_size=batch_size)\n",
        "test_gen = generator(data,\n",
        "                     lookback=lookback,\n",
        "                     delay=delay,\n",
        "                     min_index=220001,\n",
        "                     max_index=None,\n",
        "                     step=steps,\n",
        "                     batch_size=batch_size)\n",
        "#### How many steps to draw to see the validation set\n",
        "# val_steps = (220000 - 200001 - lookback)\n",
        "val_steps = 500\n",
        "#### How many steps to draw to see the test set\n",
        "# test_steps = (len(data) - 220001 - lookback)\n",
        "test_steps = 500"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfWO7s6T0tku"
      },
      "source": [
        "Let's first create a MLP baseline. Since this is a regression problem we use `mae` as the loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyCUu1H50dix",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1ca2c0-6a1c-4272-8176-49a2a0b101d8"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.Flatten(input_shape=(lookback // steps, data.shape[-1])))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(1))\n",
        "model.compile(optimizer=RMSprop(), loss='mae')\n",
        "history = model.fit(train_gen,\n",
        "                              steps_per_epoch=500,\n",
        "                              epochs=20,\n",
        "                              validation_data=val_gen,\n",
        "                              validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "500/500 [==============================] - 11s 20ms/step - loss: 2.2140 - val_loss: 0.7767\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.7497 - val_loss: 0.3436\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.3664 - val_loss: 0.3321\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.2842 - val_loss: 0.3082\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 9s 19ms/step - loss: 0.2605 - val_loss: 0.3703\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.2508 - val_loss: 0.3295\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.2429 - val_loss: 0.3277\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.2366 - val_loss: 0.3538\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.2313 - val_loss: 0.3219\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.2272 - val_loss: 0.3579\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 9s 19ms/step - loss: 0.2248 - val_loss: 0.3311\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.2202 - val_loss: 0.3286\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - 9s 19ms/step - loss: 0.2178 - val_loss: 0.3225\n",
            "Epoch 14/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.2148 - val_loss: 0.3426\n",
            "Epoch 15/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.2126 - val_loss: 0.3642\n",
            "Epoch 16/20\n",
            "500/500 [==============================] - 9s 19ms/step - loss: 0.2115 - val_loss: 0.3509\n",
            "Epoch 17/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.2067 - val_loss: 0.3383\n",
            "Epoch 18/20\n",
            "500/500 [==============================] - 10s 19ms/step - loss: 0.2072 - val_loss: 0.3419\n",
            "Epoch 19/20\n",
            "500/500 [==============================] - 10s 20ms/step - loss: 0.2020 - val_loss: 0.3535\n",
            "Epoch 20/20\n",
            "500/500 [==============================] - 10s 20ms/step - loss: 0.2007 - val_loss: 0.3401\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MByxBkB45BUi"
      },
      "source": [
        "You can see the model reach the best `val_loss` (`mae`) of `0.3263` at epoch `5`.\n",
        "\n",
        "Since the model overfitted easily (with is common in time series analysis or regression models), we consider using a `EarlyStopping` below (See L4 for more details)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGnKRfdF08_F"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hwiaFV5-s_Y"
      },
      "source": [
        "So we can build out first recurrent baseline, with a `GRU` layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtzHmJgr-yYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65d55e3e-d165-4f1a-f1cd-70da86659147"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.GRU(32, input_shape=(None, data.shape[-1])))\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer=RMSprop(), loss='mae')\n",
        "history = model.fit(train_gen,\n",
        "                              steps_per_epoch=500,\n",
        "                              epochs=20,\n",
        "                              validation_data=val_gen,\n",
        "                              validation_steps=val_steps,\n",
        "                              callbacks=[es]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "500/500 [==============================] - 18s 26ms/step - loss: 0.3184 - val_loss: 0.2453\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 13s 26ms/step - loss: 0.2853 - val_loss: 0.2464\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 13s 26ms/step - loss: 0.2762 - val_loss: 0.2443\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 13s 26ms/step - loss: 0.2746 - val_loss: 0.2406\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.2671 - val_loss: 0.2531\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 14s 27ms/step - loss: 0.2629 - val_loss: 0.2504\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.2578 - val_loss: 0.2406\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.2545 - val_loss: 0.2462\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 13s 27ms/step - loss: 0.2502 - val_loss: 0.2566\n",
            "Epoch 00009: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRJYz5Lkczgu"
      },
      "source": [
        "Albeit the better results, we can see we still have serious __overfitting__ problem.\n",
        "\n",
        "From L4 we know another way to fight the overfitting problem is to use `Dropout`. In RNN models, we can use recurrent dropout within the RNN layer, rather than using a separate `Dropout` layer.\n",
        "\n",
        "See example below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcV3YZiHBaNf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "outputId": "7be2c720-ba17-4381-a3a9-943792c6e74c"
      },
      "source": [
        "#### takes time to run !!!\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "model.add(layers.GRU(32,\n",
        "                     dropout=0.2, # general dropouts\n",
        "                     recurrent_dropout=0.2, # dropouts applied to every step\n",
        "                     input_shape=(None, data.shape[-1])))\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer=RMSprop(), loss='mae')\n",
        "history = model.fit(train_gen,\n",
        "                              steps_per_epoch=500,\n",
        "                              epochs=40,\n",
        "                              validation_data=val_gen,\n",
        "                              validation_steps=val_steps,\n",
        "                              callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/40\n",
            "500/500 [==============================] - 359s 703ms/step - loss: 0.3504 - val_loss: 0.2627\n",
            "Epoch 2/40\n",
            "500/500 [==============================] - 348s 696ms/step - loss: 0.3052 - val_loss: 0.2596\n",
            "Epoch 3/40\n",
            "500/500 [==============================] - 347s 694ms/step - loss: 0.3009 - val_loss: 0.2593\n",
            "Epoch 4/40\n",
            "500/500 [==============================] - 348s 697ms/step - loss: 0.2959 - val_loss: 0.2482\n",
            "Epoch 5/40\n",
            "500/500 [==============================] - 345s 691ms/step - loss: 0.2928 - val_loss: 0.2578\n",
            "Epoch 6/40\n",
            "500/500 [==============================] - 346s 693ms/step - loss: 0.2864 - val_loss: 0.2612\n",
            "Epoch 7/40\n",
            "500/500 [==============================] - 347s 695ms/step - loss: 0.2818 - val_loss: 0.2584\n",
            "Epoch 8/40\n",
            "500/500 [==============================] - 347s 694ms/step - loss: 0.2784 - val_loss: 0.2496\n",
            "Epoch 9/40\n",
            "362/500 [====================>.........] - ETA: 1:28 - loss: 0.2757"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-f8b692dad945>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                               \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                               callbacks=[es])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DtMR23reyjj"
      },
      "source": [
        "You see the warning above? That's because the version of Nvidia's cuDNN does not support `recurrent_dropout`. You can always install a newer version, hopefull that would solve the problem - to increase the training time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CXVppKxspBV"
      },
      "source": [
        "### Stacked Recurrent Layers\n",
        "\n",
        "- With using `Dropout` to handle the overfitting issue, we can actually make our model(s) more complex, in search for __better performance__\n",
        "- Increasing the model complexity (e.g., number of layers or number of neurons in each layer), aka. capacity, can let the model capture more complex patterns, or deeper\n",
        "\n",
        "__PRO TIP__: however, increasing model capacity cannot guarantee better performance.\n",
        "\n",
        "- Usually the powerful RNN models using multiple RNN layers\n",
        "  - This is very straigtforward, you just stack these layers one after another\n",
        "  - One key features is you have to use `return_sequences` to connect the _output_ from the previous RNN layer to the _input_ of the subsequent layer\n",
        "- See below illustrative example to understand how `return_sequences` works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8upHgLVdP5-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9210e398-bd2a-4e1b-ee59-08d0d4126525"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import LSTM\n",
        "import numpy as np\n",
        "#### Note that we use the Functional API here `Model`\n",
        "#### define model\n",
        "inputs1 = Input(shape=(3, 1))\n",
        "lstm1 = LSTM(1)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "#### define input data\n",
        "data = np.array([0.1, 0.2, 0.3]).reshape((1,3,1))\n",
        "#### make and show prediction\n",
        "model.predict(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03304904]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0zLOHWMkSBR"
      },
      "source": [
        "You can see the output of the LSTM layer, without `return_sequences`, is an $n$-d vector, where the shape of the input data is ($n , m$). In other words, LSTM \"squeezes\" the input data.\n",
        "\n",
        "However, to stack RNN (e.g., LSTM) layers together, we need to make sure the output of the previous layer is the same of the input data (i.e., ($n , m$)). That's why we use `return_sequences`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFGEfPuEkNpn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2988f8-fb76-4a80-ff7d-8f0065565ab7"
      },
      "source": [
        "#### define model\n",
        "inputs1 = Input(shape=(3, 1))\n",
        "lstm1 = LSTM(1, return_sequences=True)(inputs1)\n",
        "model = Model(inputs=inputs1, outputs=lstm1)\n",
        "#### define input data\n",
        "data = np.array([0.1, 0.2, 0.3]).reshape((1,3,1))\n",
        "#### make and show prediction\n",
        "model.predict(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.0141936 ],\n",
              "        [-0.03891549],\n",
              "        [-0.07043877]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn3b3aD2lJiB"
      },
      "source": [
        "See the shape of the output is `(1, 3)`, as the same as the input data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGTAen1vlT3_"
      },
      "source": [
        "Now Let's use stacked `GRU` layers on our temperature forecasting problem.\n",
        "\n",
        "Below code shows how it's done\"\n",
        "\n",
        "```python\n",
        "model = Sequential()\n",
        "model.add(GRU(32,\n",
        "                     dropout=0.1,\n",
        "                     recurrent_dropout=0.5,\n",
        "                     return_sequences=True,\n",
        "                     input_shape=(None, data.shape[-1])))\n",
        "#### stacked GRU here\n",
        "model.add(GRU(64, activation='relu',\n",
        "                     dropout=0.1,\n",
        "                     recurrent_dropout=0.5))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(optimizer=RMSprop(), loss='mae')\n",
        "history = model.fit(train_gen,\n",
        "                    steps_per_epoch=500,\n",
        "                    epochs=40,\n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=val_steps,\n",
        "                    callbacks = [es])\n",
        "```\n",
        "\n",
        "Refer to Figure 6.23 in your textbook for the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqf6-afbw6MD"
      },
      "source": [
        "We can see that the more complex model (stacked RNN) yield slightly better results. Actually, you should understand a lot of the pre-trained models, like the `VGG-16` model we saw, or the [transformer models](https://www.analyticsvidhya.com/blog/2019/06/understanding-transformers-nlp-state-of-the-art-models/) we used in NLP, have multiple stacked layers for better performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncx2cB5Mw_4y"
      },
      "source": [
        "### Bidirectional RNNs\n",
        "\n",
        "- To further improve the performance of the RNNs, we use a special technique called __bidirectional RNN__\n",
        "  - Which captures the sequence from both directions (e.g., from both left-right and right-left)\n",
        "  - This is because of the dependency are usually bidirectional, say the words before and after determine the word in between\n",
        "- Traditional RNNs are __order dependent__\n",
        "  - They process the sequence in order, you cannot shift, reverse, or shuffle the order: since the sequence becomes are different data\n",
        "  - The order is meaningful - means order is part of the __pattern__\n",
        "- In a lot of the cases, such as the weather forecasting problem, the reversed order does not make a lot of sense (refer to Figure 6.24 for the results)\n",
        "  - But in other scenarios, such as NLP, we use bidirectional RNNs a lot (refer to listing 6.42 for an example)\n",
        "\n",
        "__PRO TIP:__ You should consider using bidirectional RNN when you are analyzing text data. Additionally, if you can find a representation of the data, you should always use it.\n",
        "\n",
        "- Let's see whether a Bidirectional GRU model can help us forecasting the temperature\n",
        "  - Refer to the textbook for a NLP example on the IMDB data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERSwssPDlfEK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d112a6aa-1d20-480a-92fd-061a59d38b9f"
      },
      "source": [
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "#### Bidirectional is a wrapper that can be applied to any RNN layer\n",
        "model.add(layers.Bidirectional(\n",
        "    layers.GRU(32), input_shape=(None, data.shape[-1])))\n",
        "model.add(layers.Dense(1))\n",
        "\n",
        "model.compile(optimizer=RMSprop(), loss='mae')\n",
        "history = model.fit(train_gen,\n",
        "                              steps_per_epoch=500,\n",
        "                              epochs=40,\n",
        "                              validation_data=val_gen,\n",
        "                              validation_steps=val_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "500/500 [==============================] - 21s 35ms/step - loss: 0.2915 - val_loss: 0.2550\n",
            "Epoch 2/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.2729 - val_loss: 0.2403\n",
            "Epoch 3/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.2662 - val_loss: 0.2406\n",
            "Epoch 4/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.2614 - val_loss: 0.2395\n",
            "Epoch 5/40\n",
            "500/500 [==============================] - 17s 34ms/step - loss: 0.2557 - val_loss: 0.2346\n",
            "Epoch 6/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.2509 - val_loss: 0.2637\n",
            "Epoch 7/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.2427 - val_loss: 0.2550\n",
            "Epoch 8/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.2392 - val_loss: 0.2628\n",
            "Epoch 9/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.2300 - val_loss: 0.2695\n",
            "Epoch 10/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.2248 - val_loss: 0.2862\n",
            "Epoch 11/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.2183 - val_loss: 0.2839\n",
            "Epoch 12/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.2125 - val_loss: 0.3041\n",
            "Epoch 13/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.2098 - val_loss: 0.2993\n",
            "Epoch 14/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.2040 - val_loss: 0.3037\n",
            "Epoch 15/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.1976 - val_loss: 0.3022\n",
            "Epoch 16/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1948 - val_loss: 0.3143\n",
            "Epoch 17/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.1897 - val_loss: 0.3068\n",
            "Epoch 18/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.1870 - val_loss: 0.3065\n",
            "Epoch 19/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1818 - val_loss: 0.3070\n",
            "Epoch 20/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1783 - val_loss: 0.3183\n",
            "Epoch 21/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1740 - val_loss: 0.3012\n",
            "Epoch 22/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1718 - val_loss: 0.3243\n",
            "Epoch 23/40\n",
            "500/500 [==============================] - 18s 36ms/step - loss: 0.1685 - val_loss: 0.3153\n",
            "Epoch 24/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1645 - val_loss: 0.3248\n",
            "Epoch 25/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1619 - val_loss: 0.3193\n",
            "Epoch 26/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1604 - val_loss: 0.3134\n",
            "Epoch 27/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.1571 - val_loss: 0.3238\n",
            "Epoch 28/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.1561 - val_loss: 0.3255\n",
            "Epoch 29/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1527 - val_loss: 0.3282\n",
            "Epoch 30/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1505 - val_loss: 0.3136\n",
            "Epoch 31/40\n",
            "500/500 [==============================] - 18s 36ms/step - loss: 0.1486 - val_loss: 0.3292\n",
            "Epoch 32/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1471 - val_loss: 0.3240\n",
            "Epoch 33/40\n",
            "500/500 [==============================] - 18s 36ms/step - loss: 0.1459 - val_loss: 0.3421\n",
            "Epoch 34/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1441 - val_loss: 0.3303\n",
            "Epoch 35/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1420 - val_loss: 0.3529\n",
            "Epoch 36/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1403 - val_loss: 0.3343\n",
            "Epoch 37/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1394 - val_loss: 0.3430\n",
            "Epoch 38/40\n",
            "500/500 [==============================] - 18s 36ms/step - loss: 0.1378 - val_loss: 0.3427\n",
            "Epoch 39/40\n",
            "500/500 [==============================] - 18s 35ms/step - loss: 0.1363 - val_loss: 0.3515\n",
            "Epoch 40/40\n",
            "500/500 [==============================] - 17s 35ms/step - loss: 0.1352 - val_loss: 0.3630\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njfyUN8u0NlF"
      },
      "source": [
        "We confirm that the bidirectional GRU does not improve the performance a lot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ok2Av54v0UeH"
      },
      "source": [
        "### YOUR TURN HERE\n",
        "\n",
        "Build your model on the IMDB dataset, with considerations of the following points:\n",
        "- Adjust the number of units in each recurrent layer in the stacked setup. The current choices are largely arbitrary and thus probably suboptimal.\n",
        "- Adjust the learning rate used by the `RMSprop` optimizer.\n",
        "- Try using `LSTM` layers instead of `GRU` layers.\n",
        "- Try using a bigger densely connected regressor on top of the recurrent layers: that is, a bigger `Dense` layer or even a stack of `Dense` layers.\n",
        "- Don’t forget to eventually run the best-performing models (in terms of `val_loss`) on the test set!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLn2QyQ-0S3W"
      },
      "source": [
        "#### Write your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYbiiY_u1ATG"
      },
      "source": [
        "## Use 1D CNN on Sequence Data\n",
        "\n",
        "- In L5, we saw how to use 2D CNN to extract 2D patches of images (as representations of them) for classification purposes\n",
        "- Similarly, we can use 1D CNN to create 1D patches of sequence data\n",
        "  - these 1D patches are __subsequences__\n",
        "  - the subsequences can capture the local dependencies (patterns) in the sequence data\n",
        "- For instance, if we create 1D patches with size of 5 on text data at the __character level__:\n",
        "  - these patches are words or words fragments of length 5 or less\n",
        "  - so we can learn word morphs using this network\n",
        "- See the illustration below:\n",
        "\n",
        "![1DCNN](https://drek4537l1klr.cloudfront.net/chollet/Figures/06fig26.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUjd_8gN8FHk"
      },
      "source": [
        "### `Conv1D` Layers\n",
        "\n",
        "- `Conv1D` layers are similar to the `Conv2D` layers\n",
        "  - they take inputs in the shape of `(samples, time, features)`\n",
        "  - Key difference compared to the `Conv2D` layers:\n",
        "    - `samples` are number of sequences in the training set\n",
        "    - `time` means steps in the sequences, such as number of words/characters\n",
        "    - `features` refer to the embedding of words/characters\n",
        "- Similar to `Conv2D` layers, every `Conv1D` layer needs to be paired up with a `MaxPooling1D` layer\n",
        "  - we say we use $ 3\\times 3$ or $5 \\times 5$ filters in `Conv2D` layers, but we use `7` or `9` filters for `Conv1D` layers\n",
        "  - Just note after the __last__ `Conv1D` layer we need to use the `GlobalMaxPooling1D` layer so the data is flatten\n",
        "- Let's use a `Conv1D` model on the IMDB dataset here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RyQQn0N76Fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c367edc-79e9-4d33-ec60-04dd0b02262a"
      },
      "source": [
        "#### load and prepare the data\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "max_features = 10000\n",
        "max_len = 500\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')\n",
        "\n",
        "print('Pad sequences (samples x time)')\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('x_test shape:', x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "25000 train sequences\n",
            "25000 test sequences\n",
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 500)\n",
            "x_test shape: (25000, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXQ2Wxr_9qGX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5509f39c-936e-4d18-eac2-3d0af21febc8"
      },
      "source": [
        "#### Build the model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, 128, input_length=max_len))\n",
        "model.add(Conv1D(32, 7, activation='relu'))\n",
        "model.add(MaxPooling1D(5))\n",
        "model.add(Conv1D(32, 7, activation='relu'))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 500, 128)          1280000   \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 494, 32)           28704     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 98, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 92, 32)            7200      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,315,937\n",
            "Trainable params: 1,315,937\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9v8SyPC996z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "115969ef-4504-4e99-d1c8-ed03dbdc3b8b"
      },
      "source": [
        "#### compile and train\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(optimizer=RMSprop(lr=1e-4),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=10,\n",
        "                    batch_size=128,\n",
        "                    validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 33s 38ms/step - loss: 0.7686 - acc: 0.5170 - val_loss: 0.6856 - val_acc: 0.5576\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 6s 35ms/step - loss: 0.6676 - acc: 0.6596 - val_loss: 0.6687 - val_acc: 0.6474\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 6s 35ms/step - loss: 0.6310 - acc: 0.7539 - val_loss: 0.6350 - val_acc: 0.6534\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 0.5568 - acc: 0.8022 - val_loss: 0.5253 - val_acc: 0.7848\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 0.4313 - acc: 0.8397 - val_loss: 0.4351 - val_acc: 0.8324\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 0.3509 - acc: 0.8716 - val_loss: 0.4158 - val_acc: 0.8512\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 6s 35ms/step - loss: 0.3062 - acc: 0.8913 - val_loss: 0.4104 - val_acc: 0.8580\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 6s 35ms/step - loss: 0.2729 - acc: 0.9046 - val_loss: 0.4204 - val_acc: 0.8600\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 5s 35ms/step - loss: 0.2435 - acc: 0.9155 - val_loss: 0.4158 - val_acc: 0.8632\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 6s 35ms/step - loss: 0.2227 - acc: 0.9249 - val_loss: 0.4360 - val_acc: 0.8696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy6n-_ZqHg59"
      },
      "source": [
        "### Combining `CNN` with `LSTM` Layers\n",
        "\n",
        "- Since `1DCNN` captures the __patterns__ within the subsequences\n",
        "  - they do not capture the dependencies between the subsequences\n",
        "- One solution is to stack a lot of `CNN` layers together\n",
        "  - but that would subject your model(s) to overfitting\n",
        "  - and the model can only capture the __weak__ dependencies between the subsequences\n",
        "- Refer to Listing 6.47 and Figure 6.29 on the textbook for an example of using `1DCNN` on the weather forecasting data\n",
        "  - The results are fairly inferior since the model cannot capture the temporal relationships in the data\n",
        "  - In the IMDB sentiment classification problem, since the sentiment signals are at the word level, the problem is not as severe\n",
        "- The solution is to combine the `1DCNN` with `RNN` layers, see below:\n",
        "\n",
        "![CNNLSTM](https://drek4537l1klr.cloudfront.net/chollet/Figures/06fig30.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMBgY3aYVWdM"
      },
      "source": [
        "Even though this architecture is not as popular as pure CNN or LSTM, it is gaining more attractions recently.\n",
        "\n",
        "Let's illustrate it using the weather forecasting problem. One key difference is that since the CNN-LSTM model allows us to investigate longer dependencies in our data, we can either have more `lookback` data, or predict with a finer-grained data (aiming for more precision).\n",
        "\n",
        "For the purpose of illustration, we try to predict 10-days with 30 minutes intervals (rather than 1 hour used above). We need to re-design our data generators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vtNANTLI2wC"
      },
      "source": [
        "#### data generators - very similar compared to before\n",
        "step = 3\n",
        "lookback = 720\n",
        "delay = 144\n",
        "\n",
        "train_gen = generator(data,\n",
        "                      lookback=lookback,\n",
        "                      delay=delay,\n",
        "                      min_index=0,\n",
        "                      max_index=200000,\n",
        "                      shuffle=True,\n",
        "                      step=step)\n",
        "val_gen = generator(data,\n",
        "                    lookback=lookback,\n",
        "                    delay=delay,\n",
        "                    min_index=200001,\n",
        "                    max_index=220000,\n",
        "                    step=step)\n",
        "test_gen = generator(data,\n",
        "                     lookback=lookback,\n",
        "                     delay=delay,\n",
        "                     min_index=220001,\n",
        "                     max_index=None,\n",
        "                     step=step)\n",
        "#### we let the model process 128 steps at a time\n",
        "#### speed up the process, while the loss in performance\n",
        "#### can be compensated with the advanced model\n",
        "val_steps = (220000 - 200001 - lookback) // 128\n",
        "test_steps = (len(data) - 220001 - lookback) // 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmGpS--6WUs3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad1f28c-3372-4797-d9a9-a86b7a136067"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GRU, Dense\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(32, 5, activation='relu',\n",
        "                        input_shape=(None, data.shape[-1])))\n",
        "model.add(MaxPooling1D(3))\n",
        "model.add(Conv1D(32, 5, activation='relu'))\n",
        "#### note that we do not need `MaxPooling` here\n",
        "model.add(GRU(32))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_2 (Conv1D)            (None, None, 32)          192       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, None, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, None, 32)          5152      \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 32)                6336      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 11,713\n",
            "Trainable params: 11,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMX_7WKFXghq"
      },
      "source": [
        "Below is how you train and validate the model:\n",
        "\n",
        "```python\n",
        "model.compile(optimizer=RMSprop(), loss='mae')\n",
        "history = model.fit(train_gen,\n",
        "                    steps_per_epoch=500,\n",
        "                    epochs=20,\n",
        "                    validation_data=val_gen,\n",
        "                    validation_steps=val_steps,\n",
        "                    callbacks=[es])\n",
        "```\n",
        "\n",
        "Judging from the validation loss, this setup isn’t as good as the regularized GRU alone, but it’s significantly faster. It looks at twice as much data, which in this case doesn’t appear to be hugely helpful but may be important for other datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyfDkfntX_b1"
      },
      "source": [
        "# Deep Learning & Artificial Intelligence\n",
        "## Recurrent Neural Networks and Natrural Language Processing\n",
        "### Dr. Jie Tao, Fairfield University"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGiX2fS-XMBi"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}